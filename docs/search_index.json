[["index.html", "Introduction to Remote Computing Overview Introductory skills Intermediate skills Advanced skills", " Introduction to Remote Computing C. Titus Brown, Saranya Canchi, Amanda Charbonneau, Marisa Lim, Abhijna Parigi, Pamela Reynolds, and Nick Ulle. 2021-08-10 Overview Introductory skills Workshop 1: Introduction to the UNIX Command Line - Tues Aug 3 Workshop 2: Creating and modifying text files on remote computers - Wed Aug 4 Intermediate skills Workshop 3: Connecting to remote computers with ssh - Tues Aug 10 Workshop 4: Running programs on remote computers and retrieving the results - Th Aug 12 Workshop 5: Installing software on remote computers with conda - Fri Aug 13 Workshop 6: Structuring your projects for current and future you - Tues Aug 17 Workshop 7: Automating your analyses and executing long-running analyses on remote computers - Th Aug 19 Workshop 8: Keeping track of your files with version control - Tues Aug 24 Advanced skills Workshop 9: Automating your analyses with the snakemake workflow system - Wed Aug 25 Workshop 10: Executing large analyses on HPC clusters with slurm - Th Aug 26 Workshop 11: Making use of on-demand “cloud” computers from Amazon Web Services - Tues Aug 31 "],["introduction-to-the-unix-command-line.html", "1 Introduction to the UNIX Command Line 1.1 Introduction to UNIX 1.2 Navigation 1.3 Viewing &amp; Searching 1.4 File Manipulation 1.5 Some final notes", " 1 Introduction to the UNIX Command Line This two hour workshop will introduce attendees to the UNIX command line, which is the main way to interact with remote computers. We will cover computing concepts, file systems and directory structure, and some of the most important commands for working with remote computers. Today and tomorrow we’ll be using an interactive Web site running on a binder. To start your binder, please click on the “launch” button below; it will take up to a minute to start. NOTE: This lesson was adapted from Data Carpentry’s Introduction to the Command Line for Genomics lesson and the Lab for Data Intensive Biology’s Advanced Beginner/Intermediate Shell workshop. 1.1 Introduction to UNIX 1.1.1 Learning Goals visualize file/directory structures understand basic shell vocabulary gain exposure to the syntax of shell &amp; shell scripting look at the contents of a directory find features of commands with man commands: pwd, ls, cd, man 1.1.1.1 What is the shell and what is the terminal? The shell is a computer program that uses a command line interface (CLI) to give commands made by your keyboard to your operating system. Most people are used to interacting with a graphic user interface (GUI), where you can use a combination of your mouse and keyboard to carry out commands on your computer. We can use the shell through a terminal program. Everything we can do using our computer GUI, we can do in the shell. We can open programs, run analyses, create documents, delete files and create folders. We should note that folders are called directories at the command line. For all intents and purposes they can be used interchangeably but if you’d like more information please see “The folder metaphor” section of Wikipedia. The ease of getting things done via the shell will increase with your exposure to the program. Go ahead and open a new terminal window in binder by clicking on “Terminal”. When we open up terminal in binder we will see a a line of text. This is a prompt statement. It can tell us useful things such as the name of the directory we are currently in, our username, or what computer we are currently running terminal on. Let’s take a look around. First, we can use the print working directory command see what directory we are currently located in. pwd This gives us the absolute path to the directory where we are located. An absolute path shows the complete series of directories you need to locate either a directory or a file starting from the root directory of your computer. What is the root? A useful way to start thinking about directories and files is through levels. At the highest level of your computer, you have the root directory. Everything that is contained in your computer is located in directories below your root directory. We can also look at the contents of the directory by using the ls (“list”) command: ls This command prints out a list of files and directories that are located in our current working directory. We’ve preloaded some data into the binder, so we have a subdirectory data/ that we can look at. To change the working directory, we need to use the cd (“change directory”) command. Let’s move into the data directory. cd data Let’s have a look around. ls We can see the following files: MiSeq Slide1.jpg hello.sh nano1.png README.md gvng.jpg nano2.png However, this directory contains more than the eye can see! To show hidden files we can use the -a option. ls -a We will see the following: . MiSeq Slide1.jpg hello.sh nano1.png .. README.md gvng.jpg .hidden nano2.png Three new items pop up ., .. and .hidden. Using options with our commands allows us to do a lot! But how did we know to add -a after ls? Most commands offer a --help. Let’s look at the available options that ls has: ls --help Here we see a long list of options. Each option will allow us to do something different. CHALLENGE Try to find the option that allows you to differentiate between directories and executable files when using ls. Hint: look for the word classify. (You can also look at the ls man page if you prefer! We can also combine commands: ls -aFl This combination of options will list all the contents of the directory and differentiate between file types. 1.2 Navigation 1.2.1 Learning Goals paths look at the contents of files perform functions outside of the directory you are in intro to the wildcard expression: * copy, move and remove files create and remove directories understand the structure of commands commands: cat, cp, mv, rm, mkdir Now we have seen how to navigate around our computers and seeing what is located in the directory we are. But some of the beauty of the shell is that we can execute activities in locations that we are not currently in. To do this we can either use an absolute path or a relative path. A relative path is the path to another directory from the the one you are currently in. Navigate into the tmp1 directory located in the .hidden directory. cd .hidden/tmp1 Here we see two files notit.txt and thisinnotit.txt. We can see what is in the directories using the cat command which concatenates and prints the content of the file we list. cat thisinnotit.txt This is not the text file you&#39;re looking for NOTE - you can use TAB to do filename completion, so if you type cat this and then press your Tab key once, it will autocomplete if there is a unique match. If there is more than one match, the first Tab will do nothing, and the second will show all the possible matches. Let’s see what else is in the other tmp directories: ls ../tmp2 and we can see the contents of tmp3 ls ../tmp3 So, even though we are in the tmp1/ directory, we can see what is in other directories by using the relative path to the directory of interest. Note we can also use absolute paths too. You may have noticed the ../ this is how to get to the directory above the one you are currently located in. Note: in this case, we have access to the RStudio file browser, too, which is really nice. But in the future we won’t. So we can use the file browser today, but on Farm we’ll have to get by with just the command line interface and no other interface! CHALLENGE: Use the absolute path to list the files in the tmp2 directory. Wouldn’t it be nice to see the contents of all the tmp directories at once? We can use a regular expression to capture a sequence of characters (like the numbers 1, 2 and 3 at the end of the tmp directories). We can use the wild card character *, which expands to match any amount of characters. ls ../tmp* ../tmp1: notit.txt thisinnotit.txt ../tmp2: anotherfile.txt ../tmp3: closebutnotit.txt youfoundit.txt So, even though we are in the tmp1 directory we can use a relative path. We are quite used to moving, copying and deleting files using a GUI. All of these functions can be carried out at the command line with the following commands: Copy files with the cp command by specifying a file to copy and the location of the copied file. Here we will copy the thisinnotit.txt into the file thisisacopy.txt. cp thisinnotit.txt thisisacopy.txt The syntax for the copy command is cp &lt;source_file&gt; &lt;destination_file&gt;. Using this syntax we can copy files to other directories as well: cp thisinnotit.txt ../tmp2 If we navigate to the tmp2 directory and list the files that are in it we will see the thisinnotit.txt file has been copied to the tmp2 directory. cd ../tmp2 ls -l CHALLENGE: Use the mv command to move the thisinnotit.txt file from tmp2 to tmp3. Once we know how to copy and move files, we can also copy and move directories. We can create new directories with the command mkdir. Let’s make a new directory called tmp4 cd ../ mkdir tmp4 ls -l The shell is quite powerful and can create multiple directories at once. It can create multiple directories in the current working directory: mkdir tmp5 tmp6 ls -l or it can create a series of directories on top of one another: mkdir -p how/deep/does/the/rabbit/hole/go We can use tab complete to get to the go directory. Type cd h then hit tab. If you hit tab enough times your command will eventually read: cd how/deep/does/the/rabbit/hole/go/ You can see that we’ve created a bit of a monster directory structure… CHALLENGE: Navigate to the data directory and use the rm command to remove the how directory and all its contents. This nicely hints at the power of the shell - you can do certain things (in this case, create a nested hierarchy of directories) much more easily in the shell. But that power cuts both ways - you can also mess things up more easily in the shell! 1.3 Viewing &amp; Searching 1.3.1 Learning Goals looking inside files search for keywords within files commands: less, head, tail, grep A big part of data science is making sure what you expect in a particular file is what you have in that file. There are a few ways to look at the contents of a file. We’ve already seen how to print the entirety of a file to the stdout of our cat command. We can also look at files using the less command. Less is a safe way of looking at the contents of a file without the ability to change it. (We’ll talk more about text files and editing them in the second workshop!) Starting from the data/ directory in our home directory cd ~/data/ let’s look at some sequence data in a fastq file format. cd MiSeq less F3D0_S188_L001_R1_001.fastq We can see a bunch of sequence data! Use the up, down, left and right arrows to look through the folder a bit. Then press q to quit less. A lot of the time we want to know if a file contains what we expect. Many of the sequence files in this directory have the file ending .fastq. We expect these files to contain information in a particular format throughout the file with four lines of information for each sequence string. Looking through a million line file using less will take a long time. Rather than manually looking through the file we can print only a portion of the files contents to the terminal: head F3D0_S188_L001_R1_001.fastq @M00967:43:000000000-A3JHG:1:1101:18327:1699 1:N:0:188 NACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGCCTGCCAAGTCAGCGGTAAAATTGCGGGGCTCAACCCCGTACAGCCGTTGAAACTGCCGGGCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACCCCGATTGCGAAGGCAGCATACCGGCGCCCTACTGACGCTGAGGCACGAAAGTGCGGGGATCAAACAG + #&gt;&gt;AABABBFFFGGGGGGGGGGGGGGGGHHHHHHHGGGHHHHHGHGGGGGGGHGGGGGGHHHHHHHHHHGGGGGHHHHGHGGGGGGHHBGHGDGGGGGHHHGGGGHHHHHHHHGGGGGHG@DHHGHEGGGGGGBFGGEGGGGGGGG.DFEFFFFFFFDCFFFFFFFFFFFFFFFFFFFFFFFFFFDFDFFFEFFCFF?FDFFFFFFFFAFFFFFFFFFFFBDDFFFFFEFADFFFFFBAFFFA?EFFFBFF @M00967:43:000000000-A3JHG:1:1101:14069:1827 1:N:0:188 TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGCCTGCCAAGTCAGCGGTAAAATTGCGGGGCTCAACCCCGTACAGCCGTTGAAACTGCCGGGCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACCCCGATTGCGAAGGCAGCATACCGGCGCCCTACTGACGCTGAGGCACGAAAGTGCGGGGATCAAACAG + 3AA?ABBDBFFBEGGEGGGGAFFGGGGGHHHCGGGGGGHFGHGGCFDEFGGGHGGGEGF1GGFGHHHHHGGEGGHHHHHFGGGGGGHHHHHGGGGCDDGHHGGGFHHHHHHHHCD@CCHGGGGHEHGGG@GFGGGGGGG@BGGGEGCEBFFFBFFB;9@EFFFEFFFFFFFFFFFFAFBBBFFFFFBBBFFFFBBBFFFFFFFFFFFBBBBBBBFFFFFFFFFDDFAFFFFF.AF9/FBBBBB.EAFFE?F @M00967:43:000000000-A3JHG:1:1101:18044:1900 1:N:0:188 TACGGAGGATGCGAGCGTTGTCCGGAATCACTGGGCGTAAAGGGCGCGTAGGCGGTTTAATAAGTCAGTGGTGAAAACTGAGGGCTCAACCCTCAGCCTGCCACTGATACTGTTAGACTTGAGTATGGAAGAGGAGAATGGAATTCCTAGTGTAGCGGTGAAATGCGTAGATATTAGGAGGAACACCAGTGGCGAAGGCGATTCTCTGGGCCAAGACTGACGCTGAGGCGCGAAAGCGTGGGGAGCAAACA head prints the first ten lines of a file out onto your screen. We can look at the last ten lines of a file using the tail command: tail F3D0_S188_L001_R1_001.fastq We can see that our fastq files look a lot different than the fasta files: head HMP_MOCK.v35.fasta &gt;A.baumannii.1 TGGGGAATATTGGACAATGGGGGGAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTATGGTTGTAAAGCACTTTAAGCGAGGAGGAGGCTACTTTAGTTAATACCTAGAGATAGTGGACGTTACTCGCAGAATAAGCACCGGCTAACTCTGTGCCAGCAGCCGCGGTAATACAGAGGGTGCGAGCGTTAATCGGATTTACTGGGCGTAAAGCGTGCGTAGGCGGCTTATTAAGTCGGATGTGAAATCCCCGAGCTTAACTTGGGAATTGCATTCGATACTGGTGAGCTAGAGTATGGGAGAGGATGGTAGAATTCCAGGTGTAGCGGTGAAATGCGTAGAGATCTGGAGGAATACCGATGGCGAAGGCAGCCATCTGGCCTAATACTGACGCTGAGGTACGAAAGCATGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCATGCCGTAAACGATGTCTACTAGCCGTTGGGGCCTTTGAGGCTTTAGTGGCGCAGCTAACGCGATAAGTAGACCGCCTGGGGAGTACGGTC &gt;A.odontolyticus.1 TGGGGAATATTGCACAATGGGCGAAAGCCTGATGCAGCGACGCCGCGTGAGGGATGGAGGCCTTCGGGTTGTAAACCTCTTTCGCTCATGGTCAAGCCGCAACTCAAGGTTGTGGTGAGGGTAGTGGGTAAAGAAGCGCCGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGCGCGAGCGTTGTCCGGAATTATTGGGCGTAAAGGGCTTGTAGGCGGTTGGTCGCGTCTGCCGTGAAATCCTCTGGCTTAACTGGGGGCGTGCGGTGGGTACGGGCTGACTTGAGTGCGGTAGGGGAGACTGGAACTCCTGGTGTAGCGGTGGAATGCGCAGATATCAGGAAGAACACCGGTGGCGAAGGCGGGTCTCTGGGCCGTTACTGACGCTGAGGAGCGAAAGCGTGGGGAGCGAACAGGATTAGATACCCTGGTAGTCCACGCTGTAAACGTTGGGCACTAGGTGTGGGGGCCACCCGTGGTTTCTGCGCCGTAGCTAACGCTTTAAGTGCCCCGCCTGGGGAGTACGGCC &gt;B.cereus.1 TAGGGAATCTTCCGCAATGGACGAAAGTCTGACGGAGCAACGCCGCGTGAGTGATGAAGGCTTTCGGGTCGTAAAACTCTGTTGTTAGGGAAGAACAAGTGCTAGTTGAATAAGCTGGCACCTTGACGGTACCTAACCAGAAAGCCACGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAATTATTGGGCGTAAAGCGCGCGCAGGTGGTTTCTTAAGTCTGATGTGAAAGCCCACGGCTCAACCGTGGAGGGTCATTGGAAACTGGGAGACTTGAGTGCAGAAGAGGAAAGTGGAATTCCATGTGTAGCGGTGAAATGCGTAGAGATATGGAGGAACACCAGTGGCGAAGGCGACTTTCTGGTCTGTAACTGACACTGAGGCGCGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGAGTGCTAAGTGTTAGAGGGTTTCCGCCCTTTAGTGCTGAAGTTAACGCATTAAGCACTCCGCCTGGGGAGTACGGCC &gt;B.vulgatus.1 TGAGGAATATTGGTCAATGGGCGCAGGCCTGAACCAGCCAAGTAGCGTGAAGGATGACTGCCCTATGGGTTGTAAACTTCTTTTATAAAGGAATAAAGTCGGGTATGGATACCCGTTTGCATGTACTTTATGAATAAGGATCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGATGTTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTGCAGTTGATACTGGATATCTTGAGTGCAGTTGAGGCAGGCGGAATTCGTGGTGTAGCGGTGAAATGCTTAGATATCACGAAGAACTCCGATTGCGAAGGCAGCCTGCTAAGCTGCAACTGACATTGAGGCTCGAAAGTGTGGGTATCAAACAGGATTAGATACCCTGGTAGTCCACACGGTAAACGATGAATACTCGCTGTTTGCGATATACGGCAAGCGGCCAAGCGAAAGCGTTAAGTATTCCACCTGGGGAGTACGCCG &gt;B.vulgatus.2 TGAGGAATATTGGTCAATGGGCGAGAGCCTGAACCAGCCAAGTAGCGTGAAGGATGACTGCCCTATGGGTTGTAAACTTCTTTTATAAAGGAATAAAGTCGGGTATGGATACCCGTTTGCATGTACTTTATGAATAAGGATCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGATGTTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTGCAGTTGATACTGGATATCTTGAGTGCAGTTGAGGCAGGCGGAATTCGTGGTGTAGCGGTGAAATGCTTAGATATCACGAAGAACTCCGATTGCGAAGGCAGCCTGCTAAGCTGCAACTGACATTGAGGCTCGAAAGTGTGGGTATCAAACAGGATTAGATACCCTGGTAGTCCACACGGTAAACGATGAATACTCGCTGTTTGCGATATACGGCAAGCGGCCAAGCGAAAGCGTTAAGTATTCCACCTGGGGAGTACGCCG Each sequence entry for a fasta formatted file contains only two lines of information for each sequence string. Another useful thing to do is to be able to search the contents of files for a particular string of characters you would like to find. Let’s say you’d like to find the sequence CATTAG in your files. We can use the file pattern searcher grep to look for our favorite sequence: grep CATTAG F3D0_S188_L001_R2_001.fastq We can also use the wildcard regular expression to search CATTAG in all of the fastq files located in our current working directory: grep CATTAG *.fastq CHALLENGE: What line does CATTAG occur on in F3D141_S207_L001_R1_001.fastq? (HINT: Use grep --help to search for grep options related to line number) 1.4 File Manipulation 1.4.1 Learning Goals commands for, basename, echo 1.4.2 Renaming a bunch of files Let’s make sure we’re in the right directory- the one that contains all of our data files. cd ~/data/MiSeq For our first task, let’s pretend that we want to rename all of the fastq files to be .fq files instead (this is a surprisingly useful specific skill, even if you can’t immediately think of why you would want to do that!). Here, we get to use two of my favorite commands - ‘for’ and ‘basename’. for lets you do something to every file in a list. To see it in action: for i in *.fastq do echo $i done This is running the command echo for every value of the variable ‘i’, which is set (one by one) to all the values in the expression *.fastq. If we want to get rid of the extension ‘.fastq’, we can use the basename command: for i in *.fastq do basename $i .fastq done Now, this doesn’t actually rename the files - it just prints out the name, with the suffix ‘.fastq’ removed. To rename the files, we need to capture the new name in a variable: for i in *.fastq do newname=$(basename $i .fastq).fq echo $newname done What $( ... ) does is run the command in the middle, and then replace the $( ) with the output of running the command. Now we have the old name ($i) and the new name ($newname) and we’re ready to write the rename command – for i in *.fastq do newname=$(basename $i .fastq).fq echo mv $i $newname done Question: why did I put echo here? Now that we’re pretty sure it all looks good, let’s run it for realz: for i in *.fastq do newname=$(basename $i .fastq).fq mv $i $newname done and voila, we have renamed all the files! Side note: you may see backquotes used instead of $(...). It does the same thing but is trickier to get right, so we teach $(...) instead of `. 1.5 Some final notes This lesson focused on file and directory exploration because that’s something everyone needs to know, and all these commands will work on pretty much any computer that is running a UNIX compatible shell (including Mac OS X and Windows Subsystem for Linux). We’ll get into a broader range of tasks soon, promise! The binder and this documentation page will stay working for the foreseeable future, so please feel free to come back and revisit some of these commands! We will explore more UNIX commands over the next few workshops! Google (and especially stackoverflow) is your friend! Use Internet search whenever you have questions about what a command does, or what commands to use to achieve a particular tasks. "],["creating-and-modifying-text-files-on-remote-computers.html", "2 Creating and modifying text files on remote computers 2.1 Text files vs other files 2.2 Big Powerful Editors 2.3 Remote vs local, and why editors? 2.4 Editors that run locally on your laptop/desktop 2.5 Thinking about editors as a means to an end 2.6 Other ways to create, edit, filter, and modify files 2.7 Working with CSV files 2.8 A quick primer on compression. 2.9 Concluding thoughts", " 2 Creating and modifying text files on remote computers This two hour workshop will introduce attendees to the concepts and skills needed to create, modify, and search text files on remote computers. We will discuss files and content types, and cover the most common ways to work with remote text files. As with the first workshop introducing the UNIX command line, we’ll be using an interactive Web site running on a binder. To start your binder, please click on the “launch” button below; it will take up to a minute to start. Once it’s launched, go to the “Terminal” tab. 2.1 Text files vs other files Text files are a fairly narrow but very important subset of the kinds of files that we will work with in data science. Text files are, loosely defined, files that are human-readable without any special machine interpretation needed - such as text-only e-mails, CSV files, configuration files, and Python and R scripts. The list above is interesting, because it makes the point that just because a human can “read” the files doesn’t mean that they are intended for humans, necessarily. For example, CSV files can be more or less strictly defined in terms of formatting, and Python and R scripts still need to be valid Python or R code. DNA sequence data files like we saw yesterday are another case in point - it’s pretty rare (and a bad idea) to edit them manually, but you could if you really wanted to. The operational distinction really comes down to this: text files can be created, edited, changed, and otherwise manipulated with text-format based tools, like text editors, grep (which we saw yesterday), and other programs. Text files are a common and standard format that many tools can interact with. In comparison, binary files are files that need special programs to interact with them. Some of them are more standard than others - for example, Word files can be read or written by many programs. Images (JPG and PNG and…) can be manipulated by many programs as well. Zip files are another semi-standard format that can be manipulated by several different programs. The main thing is that you can’t just look at them with standard text-focused tools - and typically this is because binary files are meant to be used for different kinds of data than text. As a side note, one of the most important aspects of text files is that there are some really powerful tools for tracking changes to them, and collaboratively editing them - we’ll cover that in workshop 8, version control! 2.1.1 OK, OK, what does this all mean in practice? Let’s look at a simple text file - 2cities/README.md: cat 2cities/README.md As you may remember, ‘cat’ (short for ‘catenate’) displays the content of the file. This is a file in a format called Markdown, that is a lightly decorated text file with a title and so on. While it can be nicely formatted by an interpreting program (see the way github renders this file!, it can also just be viewed and read with cat. This is different from the other file in 2cities/; take a look at what’s there by running, ls 2cities/ and you should see README.md book.txt.gz In this directory, there is one text file and one binary file. If you want to see if it’s a file type that UNIX recognizes you can run the file command, e.g. file 2cities/README.md will report that it’s ASCII text, while file 2cities/book.txt.gz will report that it’s “gzip compressed data”, which is a compressed data type. What do we do with that? 2.1.2 Working with gzipped files gzip is a common type of file, and all that it means is that it’s been compressed (made smaller) with the gzip program. Look at it’s file size first – ls -lh 2cities/book.txt.gz and you’ll see that it’s about 300k. You can uncompress a gzip file with gunzip; in this case, gunzip 2cities/book.txt.gz will produce 2cities/book.txt CHALLENGE: what two commands will tell you the file type and size of 2cities/book.txt? Yep, it’s almost 3 times bigger when it’s uncompressed! And it’s file type is “UTF-8 Unicode (with BOM) text, with CRLF line terminators” which is a fancy way of saying “text, supporting extended characters (unicode), and with both a carriage return (CR) and a line feed (LF) at the end of each line.” The important thing is that pretty much any text editor should be able to edit this kind of file. Let’s take a quick look at the beginning of the file with head: head 2cities/book.txt yep, looks like text! 2.1.3 Digression: file extensions are often meaningful (but don’t have to be) Couldn’t we have guessed at what these files were based on their names? Yes, the .md extension usually means it’s a text file with Markdown formatting, and the .gz extension typically means it’s a compressed file, and the .txt extension typically means it’s a text file. So you can read book.txt.gz to mean that it’s a text file that’s been compressed. But this isn’t guaranteed - it’s a convention, rather than a requirement. Many programs will actively “sniff” the file type by looking at the content (which is what file does), and you should never blindly trust the file type indicated by the extension. 2.1.4 Let’s edit this file! Let’s start with the nano editor. nano and its sibling pico are simple text editors that let you get started, but are ultimately limited in their functionality. Note: If you’ve ever used the ‘pine’ e-mailer, you’ve used these editors! nano (and all of the editors we’ll use below in the terminal) are “text graphics” editors that give you a visual interface that is not the command line (which is good, trust us) but that also exist only within the terminal program and do not support mouse movements. This is important - you can’t use the mouse to move the cursor or make changes (although you can select things). 2.1.5 Running the editor and exiting/saving To get started, let’s open the file: nano 2cities/book.txt this will put you in an editor window. First things first: you can immediately exit by typing CTRL-X (that’s holding down the CTRL key, and then typing X, lowercase or uppercase - no shift key is needed. If you haven’t changed anything, it will simply exit. Now edit the file with nano again (use the up arrow on the command line to find and rerun the previous command!) – nano 2cities/book.txt Now change something - just type. You should see the new characters added. Use CTRL-X again, and it will ask “Save modified buffer?” If you say “No”, it will not save; if you type ‘y’, it will ask you for the name of the file. Just hit ENTER to overwrite the file you edited here. Now, you should be back at the command line. Run: head 2cities/book.txt and you should see your changes! Note, there’s no ‘undo’ possible once you’ve saved. 2.1.6 Navigating in nano Let’s go back into nano and learn how to move around. Run: nano 2cities/book.txt and use the arrow keys to move up and down and left and right. For big files, this can be tedious! If you look down on the bottom, you can see a bunch of help text telling you what control+keys to use - use CTRL-V to page down, and CTRL-Y to page back up. 2.1.7 Long lines - note! One of my least favorite features of nano is the way it handles long lines (lines that extend off the right of the screen). Try making one - go to the end of a line, and add a bunch of text. What it does is shift the whole line left while you’re typing, and then when you scroll back over to the left, it puts a $ at the last column on the screen to tell you that it’s a long line. Very confusing. But there you are. 2.1.8 Slightly more advanced features ^K will delete the current line, and ^U will put the last deleted line into the current location. (It’s a slightly janky version of cut and paste that many editors use in UNIX, for some reason.) 2.1.9 Getting help! In nano, CTRL-G will put you in “help” mode, and you can now navigate around (CTRL-V and CTRL-Y to read), and then CTRL-X to exit. Note again that ^ in front of a key means control, so e.g. ^K means “type CTRL+K” (which will delete the current line). Note also that M- means “hit Escape and then the key after”, so pressing the “escape” key, letting go of it, and then hitting “g” will go to a line and column number. Try it out - type Escape, then g, then type 500,10 and hit enter. Why do CTRL and Escape work differently? You hold down CTRL and another key, but you press Escape and then type something. Why!? The answer is that CTRL and ALT are “modifier keys”, like SHIFT - they modify the character sent when you hold them down. Escape is its own character, however, so you’re first saying “here’s an escape character!” and then “here’s another character!” (We don’t make the rules, we just explain them - sorry!) 2.1.10 Challenges: Use the help screen to answer (and experiment with) the following challenges - remember, CTRL-G gets you into help, CTRL-V pages down, and CTRL-X exits help. CHALLENGE: How do you delete the character at the current cursor position? CHALLENGE 2: How do you move to the end of the file? You can do a lot in these but as soon as you’re dealing with really large files, or many files, we suggest other editors. That having been said, we teach nano because it’s a good “basic” editor that is usually available and can almost always be used if you don’t have access to your favorite editor. 2.2 Big Powerful Editors There are two fairly dominant editors that work at the command line. They’ve been around for decades, and they have many advocates who care for them with a near-religious fervor. We will demo them for you, and point you at learning resources for them, and then leave it up to you to pick one. (We’ll probably use nano for most of the work we do in these workshops.) 2.2.1 Big Powerful Editor 1: vi ‘vi’ stands for “visual editor” and it’s available on most systems. It’s incredibly powerful, and incredibly robust, and is correspondingly cryptic and hard to use. It involves a lot of remembering specific character commands, in particular. (We’re actually using ‘vim’, but never mind that - it’s compatible with vi. Read more here.) To run vi, type: vi 2cities/book.txt (You should see all your changes from before, right?) vi starts in “normal mode”, which allows you to navigate around the file. In normal mode, what you type does not change the file - instead, it lets you issue commands to vi. The first and most important (?) command - to exit, type: :q and if there are no changes, it will simply exit. Run vi again, and let’s edit – vi 2cities/book.txt and then type ‘i’ to go to “insert” mode, and type something. Then hit the escape key to go back to “normal” mode. Now try to exit with :q. It won’t work! You have to either save, or quit. To force-quit without saving, run :q!. Now let’s learn to save! Go back and edit (i, then type something, then escape). To save, type :wq. (You can also (mystifyingly) type ZZ to do the same thing. shrug.) The main thing that vi does is give you a “normal” mode (where you can navigate around - use CTRL-F and CTRL-V to page down and up, for example) and an edit mode (use ‘i’ for insert or ‘a’ for append) where what you type goes directly into the file. You use Escape to get out of edit mode. In normal mode, ‘x’ will delete the character you’re on, and ‘dd’ will delete the line you’re on (and put it in the cut buffer), and P will pull the line out of the cut buffer into the file at the current location. And that’s what you really need to know :). A few tips for normal mode - to get help, type :help to go to a specific line, type the line number followed by G. 500G As a side note, we’ve just taught you the single most asked question on the Internet about UNIX: how to exit vi!! 2.2.2 Big Powerful Editor 2: emacs The other editor to know about is emacs. (This is what Titus uses the most.) To run emacs, emacs 2cities/book.txt This is automatically in edit mode (there’s no normal mode) so it behaves kind of like nano. To exit emacs, type CTRL-X and then CTRL-C. If you’ve modified things (by typing something), it will ask you if you want to save. To page down, type CTRL-V. To page up, type Escape V. To go to the beginning of a line, type CTRL-A. End of line, CTRL-E. (I’m telling you these specific keys because they also work at the command line.) There’s a pretty nice interactive tutorial for via that you can access with CTRL-H t (CTRL-H, followed by a ‘t’). Emacs shines when editing multiple files, but it can do a lot more, too. Some people spend their entire computing lives in emacs… see, for example, org-mode. 2.2.3 An opinion You only need to learn nano, and be basically familiar with vi and emacs. Read on for why! 2.3 Remote vs local, and why editors? So we’ve just shown you a bunch of editors that work on the command line/in the Terminal window, but don’t support mouse and copy paste and multiple windows and other nice things. Why can’t you just always use a nice editor that supports mouse commands etc etc?? Well. There are a few reasons! First is that it’s always nice to have backup options. Even if you resolutely stick with something that runs on your laptop, every now and then you may find yourself in a situation where you’re using someone else’s computer to debug or demonstrate something. Second is that these are platform independent options, in some sense - if you are connected to a UNIX system, you can pretty much always use nano or vi or emacs, no matter how you are connecting or from what type of computer. Third, sometimes it’s just faster to fix something locally in the shell. And it’s nice to have the option. Fourth, and related, is that remote file editing from your laptop or desktop requires that certain things be available on the remote computer - ssh and authentication (see next two workshops, Workshops 3 and 4!). Unfortunately, these aren’t always available - for example, we can’t actually use the nice editors on this binder, for technical reasons; we’d have to use the RStudio editor (which is also nice, but is also not always available). Last and probably least, if you’re in the Matrix and you’re Trinity and you’re trying to hack through the machine firewall after breaking into a heavily guarded compound, you’re unlikely to want to take the time to install an editor on a laptop you bring with you. Better to be able to use what’s already on the system, eh? (Yes, this is a Matrix reference.) 2.4 Editors that run locally on your laptop/desktop That all having been said, there is no reason you can’t use nice friendly editors most of the time! I asked on twitter about what editors people liked, and several popped up - Visual Studio Code was a hands-down winner. It works on Windows, Mac OS X, and Linux, and is free. BBEdit was beloved by many. Runs on Mac OS X. Free, with pay option. NotePad++ is a nice free Windows editor that I’ve used in the distant past. Some people really liked Atom too, which is free and runs on Windows, Mac OS X, and Linux. Any or all of these will work for editing remote files, support a wide variety of languages nicely, and otherwise are excellent choices. Pick one! Thrive! (We can’t use these yet because we need to configure remote access in a particular way - that will come next week :).) 2.5 Thinking about editors as a means to an end At the end of the day, whatever editor you choose needs to be one that lets you achieve your end goal - which is to quickly and reliably edit text files. I personally switch between vi and emacs on a regular basis. Emacs is where I do long-form writing and editing (because I’ve got mine configured nicely for that), while vi is what I use for quick edits (because it’s fast to start, and I don’t need to configure it at all for it to be useful - so I can use it more places). Again, most people will probably end up using something like VScode, which got many rave reviews online and supports robust syntax highlighting and many different languages, as well as remote editing. But it really doesn’t matter. I think of an editor like a kitchen - you may customize your kitchen layout and tools differently from someone else, but at the end of the day, your goal is to cook something, and you (in this analogy) only really need to worry about another editor if you’re using an unfamiliar system, just like if you’re cooking in a strange kitchen. And then it will be maddening and infuriating but that’s ok :). 2.6 Other ways to create, edit, filter, and modify files So editing is pretty cool, but if you’re in a hurry, or want to make a small change without switching windows, or need to work with some pretty big files, there are other approaches you can use. Read on! 2.6.1 Redirection, appending, and piping. By default, many UNIX commands like cat send output to something called standard out, or “stdout”. This is a catch-all phrase for “the basic place we send regular output.” (There’s also standard error, or “stderr”, which is where errors are printed; and standard input, or “stdin”, which is where input comes from.) Much of the power of the UNIX command line comes from working with stdout output, and if you work with UNIX a lot, you’ll see characters like &gt; (redirect), &gt;&gt; (append) and | (pipe) thrown around. These are redirection commands that say, respectively, “send stdout to a new file”, “append stdout to an existing file”, and “send stdout from one program to another program’s stdin.” Let’s start by going to our home directory: cd ~/ 2.6.2 The simplest possible “editor” - echo You can create a file with echo and redirection, like so: echo this is some content &gt; file.txt which will put the words this is some content in the file named file.txt. CHALLENGE: how do you view the contents of file.txt? If you then run echo this is other content &gt; file.txt it will overwrite file.txt. (Note: if you don’t like this overwriting behavior, you can run set -o noclobber so that bash will complain.) Instead of overwriting, you can append by specifying &gt;&gt;, like so – echo more content &gt;&gt; file.txt This doesn’t just work with echo - you can do this with many UNIX commands, e.g. cat file.txt file.txt &gt; newfile.txt will create newfile.txt with two copies of file.txt in it, and you can add a third with cat file.txt &gt;&gt; newfile.txt You can also e.g. search for words with grep and then save the results – for example, this will search for the word “worst” in the Tale of Two Cities, and save the results to worst-lines.txt. grep worst 2cities/book.txt &gt; worst-lines.txt 2.6.3 Piping and filtering What if you wanted to count the number of lines in which the word worst shows up in the Tale of Two Cities? You could use the “wc” (wordcount) program - grep worst 2cities/book.txt &gt; worst-lines.txt wc -l worst-lines.txt (the answer is 18 :) but this creates an unnecessary intermediate file, worst-lines.txt. You can avoid creating this file by using piping: grep worst 2cities/book.txt | wc -l which says “send the output of grep to the input of wordcount”. You’ll see this a lot in UNIX, and below we’ll explore this on a new file type - CSV files! 2.7 Working with CSV files CSV files - Comma Separated Value files - are another very common type of text files, especially in data science. Let’s explore working with them! We’ve put a list of South Park TV show quotes under SouthParkData/All-seasons.csv.gz. Let’s change into that directory to work with the CSV file. cd ~/SouthParkData Let’s now uncompress the file – remember, you can use Tab completion here by typing gunzip A&lt;TAB&gt; – gunzip All-seasons.csv.gz and look at the first few rows of the result All-seasons.csv file – head All-seasons.csv It looks like there are four columns, and the quotes are multi-line quotes. (I’ve never seen this before, but it seems to work!) Suppose you want to see if the word ‘computer’ is in there anywhere. You can use grep to do that – grep computer All-seasons.csv – and you get a lot of results! First, let’s count them: grep computer All-seasons.csv | wc -l – this will count the number of lines the word ‘computer’ shows up on. (It’s 78.) If you browse through the file, you might release that ‘Computer’ is a character on the show, but it turns out that grep is really literal and doesn’t match ‘Computer’ when you search for ‘computer’ - you need to provide ‘grep’ with ‘-i’ to do case-insensitive search! Let’s try that – grep -i computer All-seasons.csv | wc -l – and now it’s 101. How would we get at just the lines spoken by the computer? Well, if you look at the header of the file, head All-seasons.csv you’ll see that the third column is the one with the character in it. You can use the cut command to pick out just the third column by specifying comma as a separator with -d and -f3 as the field number – cut -d, -f3 All-seasons.csv | grep Computer which will give you a manageable number of results - about 16. You might note that there is an inconsistency in the way the character is named - Computer vs Computer Voice (maybe these are different characters? I don’t watch enough South Park to know…) Let’s do some counting – cut -d, -f3 All-seasons.csv | grep Computer | sort | uniq -c This is hard to pull apart but let’s do so - first, cut out column 3 then, search for Computer then, sort them alphabetically then, count the number of times each character shows up There are lots of ways this can come in handy for digging into csv files and figuring out where values are wonky. 2.7.1 Use csvtk when working with CSV files, maybe. This section was mostly to show you other ways of interacting with generic text files with CSV as an example, but if you work a lot with CSV or TSV files, I wanted to suggest looking into the csvtk program – we’ll show you how to install it with conda in workshop 5, but we pre-installed it for you on this binder. With csvtk, you can run commands that make use of column headers - for example, csvtk cut -f Character All-seasons.csv | grep Computer | sort | uniq -c gives you the same output, but it uses the header name. csvtk is a really nice piece of software that I am starting to use heavily. Highly recommended when doing a lot of CSV/TSV work - definitely check out the manual. 2.8 A quick primer on compression. Make sure you’re in the SouthParkData directory and have uncompressed All-seasons.csv – cd ~/SouthParkData gunzip All-seasons.csv (it’s ok if you’ve already run these and they fail, just want to make sure!) Text files can be large, so often they are distributed in compressed version. 2.8.1 Gzip and .gz files. gzip is a common compression format that works with .gz files. It works with one file at a time, so gzip compresses that one file and makes a new .gz file. To compress All-seasons.csv with gzip, you can use: gzip All-seasons.csv If you try to run it again, you’ll get an error message; try it! gzip All-seasons.csv …because the file no longer exists - it’s been compressed into a new file, All-seasons.csv.gz! If you run gunzip, it will uncompress the file and delete the old one. Sometimes this isn’t what you want – you can use output redirection to uncompress it and make a new copy: gunzip -c All-seasons.csv.gz &gt; All-seasons.csv but, then, if you try to run gzip All-seasons.csv it will tell you that the .gz file already exists. Say ‘n’ or use CTRL-C to exit. 2.8.2 zip and compressing multiple files. The big downside to gzip is that it works one file at a time. What if you wanted to bundle up multiple files AND compress them? Our recommended approach is to use zip to build a zip bundle or archive. This will both compress files, and store multiple files (even a directory hierarchy!) First, create the archive - cd ~/ zip -r south-park.zip SouthParkData/ (the -r is needed on some versions of zip to package up directories.) Then make a copy in a new place (just to demonstrate that it all works :) - mkdir new-place/ cd new-place/ unzip ../south-park.zip ls -R and you will see a complete new copy under ~/new-place/south-park/SouthParkData. This is handy for making quick backup copies of things and downloading them (see Workshop 4!) as well as sending people collections of files. We’ll show you a different way, using version control, in Workshop 8. Note, you can use unzip -v to see what’s in a zip archive, unzip -v ../south-park.zip and selectively unzip specific files by specifying them on the command line like so: unzip ../south-park.zip SouthParkData/README.md 2.9 Concluding thoughts What we’ve shown you is a whole plethora of hopefully not-too-confusing options for editing and working with text files. In terms of editing, the only thing you really need to do is (1) bookmark this page when you need to figure out how to exit vi, and (2) remember to use nano! The redirection and compression stuff is really useful, but again, you just need to know it exists and that there’s this tutorial on it. Taking a step back, these first two workshops have been about introductory skills that you will use every day when you use a UNIX computer. These skills may seem confusing, but they will become second nature if you use them regularly. And we’ll be doing that through the next 9 workshops! "],["connecting-to-remote-computers-with-ssh.html", "3 Connecting to remote computers with ssh 3.1 SSH and Clients 3.2 Mac OS X: Using the Terminal program 3.3 Windows: Connecting to remote computers with MobaXterm 3.4 Logging out and logging back in. 3.5 You’re logged on to a remote computer. Now what?", " 3 Connecting to remote computers with ssh This two hour workshop will show attendees how to connect to remote computers using ssh software, which is the most common way to do so. We will discuss usernames and passwords, introduce ssh software clients, and work through the most common challenges attendees will face in connecting to remote computers. @@IDEAS FOR CHALLENGES: copy a file from place a to place b, but different from day 1 edit a file and add some specific text, using an editor; point to instructions from day 2 3.1 SSH and Clients We’re going to be using SSH, the Secure Shell protocol, to connect to a remote computer - in this case, the ‘farm’ computer at UC Davis. We’ll use it for the next 7 workshops, and then in workshop 11, we’ll use ssh to connect to a computer that we rent from Amazon instead. ssh is a standard way to connect to remote computers, both to run commands and to retrieve files. It uses an encrypted connection so nothing you type can be seen by anyone else, which protects your passwords as well as any other data you send. ssh operates as a network “protocol”, which means that the sender (your local computer, in this case) and the receiver (the farm computer) can be running any software that “speaks” ssh, and they can communicate just fine. In particular, this means you can use many different software packages that speak ssh - known as ssh “clients” - and we link to some below. For our lessons, we’re going to use two specific ssh clients, one for Mac OS X that’s just called “ssh”, and one for Windows that’s called MobaXterm. We’ve chosen these because ssh comes with Mac OS X, so we don’t need to install it, and we have a lot of experience with MobaXterm. Unfortunately they’re (mostly) quite different in appearance, so we’re going to run through them separately the first time through. There are many alternatives - for example, for Mac OS X there are many different free SSH clients, and here is a list of 10 ssh clients for Windows. They will all look and feel somewhat different, but they will all get you the same place! Windows users: While we’re working through the Mac OS X ssh connection, please go to the Windows instructions and start downloading MobaXterm - thanks!. 3.2 Mac OS X: Using the Terminal program Find and open the Terminal program using Spotlight - it’s under Applications. It will look and feel a lot like the things you saw in Workshops 1 and 2 :). (Congratulations! You have unlocked a secret of Mac OS X - it’s got a command line underneath, because it’s actually a UNIX operating system!) Now type ssh farm.cse.ucdavis.edu -l datalab-XX where you replace XX with your user number (between 10 and 60). (You should received an e-mail from “Titus Brown” with the subject “Farm account name (remote computing 2021 workshop series)”. Ask a TA for help if you can’t find this e-mail.) You will be confronted with a “password:” prompt. Copy and paste in the password from your farm account e-mail. Ask a TA for help if you need it! Note that the password does not display, so it will look like nothing is being entered when you paste.) And voila, you are now logged into farm! You should be at a prompt that looks like this: datalab-09@farm:~$ 3.3 Windows: Connecting to remote computers with MobaXterm Steps: Go to the MobaXterm download page. Select “Home Edition”. Select “Portable edition”. It’s 25 MB and will take about a minute to download. Find the downloaded Zip file in your Downloads folder (should be named “MobaXterm_Personal_21.2”), and double click on it. In the MobaXterm_Personal_21.2 folder, run the MobaXterm 21.2 Application. Note: You may need to “allow access on all networks for this application” if Windows asks. Click on Session… (upper left). In the new window, click on SSH (upper left). Under “Basic SSH settings”, set “Remote host” to “farm.cse.ucdavis.edu”. This is the computer name you are connecting to. Click on “specify username”, and enter the username you received in the e-mail from “Titus Brown” with the subject “Farm account name (remote computing 2021 workshop series)”. (Ask a TA for help if you can’t find this e-mail.) Then select OK. It will now open up a terminal-looking window that will ask for your password. Select your password from your e-mail and copy it (ask a TA for help if you can’t find your password). Then use right-click to paste it. (It may open a pop-up window asking what you want right-click to do. Select the default.) Hit enter, and it should log you in! Congratulations! It will probably ask you if you want to store the password in your password store, and then ask you for a master password. You can then use this master password to “unlock” all your ssh passwords for MobaXterm to use. You can pick something short and simple to remember since (at least for now) you’ll only be using it to log into the temporary account at farm, but if you end up using MobaXterm a lot you may want to change it. 3.4 Logging out and logging back in. OK. Now that you’re in, …log out and log back in! To log out, type ‘logout’. Then go back through the above to make sure you’ve got it all right. A few notes - for Mac OS X, you can use the up arrow to go to the previous command and run it. You’ll need to type your password in again, though. for MobaXterm, you’ll be able to do use the saved password so you won’t need to type your password in again; see the screenshot below. 3.5 You’re logged on to a remote computer. Now what? The magic of UNIX and the command line is that once you’re logged onto a remote computer, …everything works the same. Yes, you will have access to different files, and maybe different software, and different compute resources (more disk space, maybe more CPUs or more memory) but the command line basically works the same whether you’re logged in to your laptop, a workstation next door, or an HPC across the world. Let’s start by reprising some of the basics from workshop 1 (the command line) and workshop 2 (editing text files). 3.5.1 Welcome to your account! Start by running: pwd and you will see something like /home/ctbrown, although it will vary with the account name you used. This is because we’re all using different accounts with different default home directories. 3.5.2 Loading some files into your account Before we go any further, we need some files! You’ll note that if you do an ls, there’s nothing in your home directory. That’s because most UNIX accounts start out empty. (Sometimes there will be generic files like “Desktop” and so on in there - it depends on the system.) Well, actually, it’s not quite empty. Try: ls -la and you’ll see a few configuration files and directories. All of these are created automatically for you and you don’t need to worry about them for now. So, basically, your account is empty of user files. So let’s get some files! There are actually many ways to download files, and we’ll show you a few over the next few workshops. We’ll start by mimicking the setup of the binders on days 1 and 2 by copying a bunch of files from GitHub into your account. The following command will take the set of files here and make them appear in your account: git clone https://github.com/ngs-docs/2021-remote-computing-binder/ – note that git and GitHub are something we’ll cover more thoroughly in week 8. For now, just accept it as one way to go out and get files :). Now if you do ls you’ll see a directory 2021-remote-computing-binder/. Let’s cd into it - cd 2021-re&lt;TAB&gt; if you hit the TAB key where it says &lt;TAB&gt;, you’ll get command-line completion to work. If you type ls -F you should see some familiar sights (at least if you attended workshops 1 and 2) - 2cities/ binder/ data/ README.md SouthParkData/ – yep, these are the files we worked with on those two days! 3.5.3 Revisiting file and path manipulation If you cd data/ and do ls you’ll see the following files: MiSeq Slide1.jpg hello.sh nano1.png README.md gvng.jpg nano2.png and with ls -a we will see the following: . MiSeq Slide1.jpg hello.sh nano1.png .. README.md gvng.jpg .hidden nano2.png Now, if you navigate into the tmp1 directory located in the .hidden directory, cd .hidden/tmp1 you will be in a different absolute directory than you were on in the binder - now it’ll be something like /home/ctbrown/2021-remote-computing-binder/data/.hidden/tmp1, rather than /home/jovyan/data/.hidden/tmp1. That’s because we’re on a different system, with a different user account than before, and (unlike with the binder) we are going to be doing more things than just exploring the contents of the binder, so we’ve put things in the folder underneath 2021-remote-computing/ to contain data for today and workshop 4. This is an example of home directory organization and project management, which we’ll be talking about in workshop 6 (project organization) - how to organize your account so that you can figure out what the files in it probably mean. At this point, you could do the rest of workshop 1’s lesson, but rather than do that, let’s just note that all of the relative path navigation you did will continue to work, even though you’re on a different computer in a different account than you were using for workshops 1 and 2. For example, you can copy files between directories using the same relative path as before, cp thisinnotit.txt ../tmp2 and we navigate to the tmp2 directory and list the files that are in it we will see the thisinnotit.txt file has been copied to the tmp2 directory. cd ../tmp2 ls -l – but the difference is that this directory is now under /home/ACCOUNT/2021-remote-computing-binder/data/ rather than /home/jovyan/data/. Try running pwd and you’ll see that: pwd 3.5.4 Revisiting file editing Now go back to the 2021-remote-computing binder directory – cd ~/2021-re&lt;TAB&gt; Here, the ~/ refers to the absolute path to your home directory, whatever your username is - it’s different for everyone in the class! - and then the 2021-remote-computing-binder/ is a directory underneath it. We can use the file command as in workshop 2 to look at the file type of 2cities/book.txt.gz – file 2cities/book.txt.gz – and then uncompress it, gunzip 2cities/book.txt.gz which will produce the uncompressed file 2cities/book.txt from the compressed file 2cities/book.txt.gz. If we run head on the .txt file, we’ll see the first 10 lines of the file: head 2cities/book.txt Conveniently, all three editors that we showed you in workshop 2 are available here - let’s use nano (or an editor of your choice) to edit the book.txt file. If you’re using nano, run nano 2cities/book.txt and use the arrow key to go down 9 lines to a blank line, and type kilroy was here! or something else silly and identifiable. Now save, using CTRL-X, then ‘y’, then ENTER. Now, if you run head 2cities/book.txt you should see that your edits are there. A difference from what we did in workshops 1 and 2 is that these changes are now persistent. Unlike binder, the files on farm don’t go away when you log out! 3.5.5 Some commands are available! Others are not. You may remember looking at the South Park CSV data set in lesson 2 - cd ~/2021-remote-computing-binder/SouthParkData/ gunzip All-seasons.csv.gz head All-seasons.csv and those commands are all standard UNIX commands. You can also use cut, grep, sort, and uniq just fine - for example, let’s calculate how many times a character in South Park (in column 3) has “computer” in its name – cut -d, -f3 All-seasons.csv | grep Computer | sort | uniq -c So those commands all work. But csvtk doesn’t – this command fails, csvtk cut -f Character All-seasons.csv | grep Computer | sort | uniq -c because csvtk isn’t installed. And that’s what we’ll be showing you how to do in workshop 5 - install software like csvtk using conda. "],["running-programs-on-remote-computers-and-retrieving-the-results.html", "4 Running programs on remote computers and retrieving the results", " 4 Running programs on remote computers and retrieving the results This two hour workshop will show attendees how to use remote computers to run their analyses, work with the output files, and copy the results back to their laptop and desktop computers. We will discuss input and output formats, where files are usually read from and written to, and how to use the ssh software to copy files to and from remote computers. "],["installing-software-on-remote-computers-with-conda.html", "5 Installing software on remote computers with conda", " 5 Installing software on remote computers with conda This two hour workshop will show attendees how to install and manage software using the conda installation system. We will give examples of installing Python and R software, and managing conda environments on remote systems. "],["structuring-your-projects-for-current-and-future-you.html", "6 Structuring your projects for current and future you", " 6 Structuring your projects for current and future you In this two hour workshop, we will discuss folder structures for organizing your projects so that you can track inputs, outputs, and processing scripts over time, and keep yourself organized as your projects evolve. "],["automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html", "7 Automating your analyses and executing long-running analyses on remote computers", " 7 Automating your analyses and executing long-running analyses on remote computers This two hour workshop will show attendees how to automate their analyses using shell scripts, as well as run and manage software that takes minutes, hours, or days to execute. We’ll also show you how to disconnect from and resume running processes using the ‘screen’ command. "],["keeping-track-of-your-files-with-version-control.html", "8 Keeping track of your files with version control", " 8 Keeping track of your files with version control This two hour workshop will show attendees how to use the git version control system to track changes to your files on the remote system, as well as backup your project files to github and transfer them to your laptop or desktop. We will demonstrate file sharing via github, and discuss ways to collaborate with a team. "],["automating-your-analyses-with-the-snakemake-workflow-system.html", "9 Automating your analyses with the snakemake workflow system", " 9 Automating your analyses with the snakemake workflow system This two hour workshop will introduce attendees to the snakemake workflow system, for executing large-scale automated analyses. "],["executing-large-analyses-on-hpc-clusters-with-slurm.html", "10 Executing large analyses on HPC clusters with slurm", " 10 Executing large analyses on HPC clusters with slurm This two hour workshop will introduce attendees to the slurm system for using, queuing and scheduling analyses on high performance compute clusters. We will also cover cluster computing concepts and talk about how to estimate the compute resources you need and measure how much you’ve used. "],["making-use-of-on-demand-cloud-computers-from-amazon-web-services.html", "11 Making use of on-demand “cloud” computers from Amazon Web Services", " 11 Making use of on-demand “cloud” computers from Amazon Web Services This two hour workshop will introduce attendees to AWS computer “instances” that let you rent compute time on large or specialized computers. We will also talk about how to estimate the compute resources you need and measure how much you’re using. "],["appendix.html", "Appendix Workshop Protocol", " Appendix Workshop Protocol Before workshop Instructor(s) create workshop notes on GitHub as an R markdown file Instructor(s) create/test computing environment (i.e., binder, Farm HPC) for workshop material Training coordinator creates pre- and post-workshop assessment surveys, with input from instructor(s) Training coordinator emails notes, pre-workshop survey, and Zoom link to participants the day before the workshop During workshop Moderator begins by asking everyone to fill out the pre-workshop survey if they haven’t already, and to put up a raised hand Zoom reaction when they’ve completed the survey. Then, describe ways to ask for help during the workshop: 1) type in Zoom chat to everyone or as a direct message to moderator/helpers (introduce helpers), 2) unmute and ask; say that we prefer participants don’t use the raised hand reaction to ask a question, since that’s used for checking in. At this point, there should be a majority of raised hands up for the survey question. Turn over the mic to the instructor. Moderator will keep track of chat questions, time (including a 5-minute break ~10:15 or 10:30am), and help share workshop resource links (i.e., section of workshop notes, exercises, post-workshop survey) Helpers aide in tracking chat questions and participation during check ins (i.e., direct message participants who have not raised their hands to make sure they’re still following along) Training team writes down typos, suggestions, etc. for the workshop and notes in the associated GitHub issue After workshop Training team updates workshop notes as needed Training coordinator emails notes, workshop recording, and post-workshop survey link to participants some time after the workshop "]]
