<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10 Executing large analyses on HPC clusters with slurm | Introduction to Remote Computing</title>
  <meta name="description" content="10 Executing large analyses on HPC clusters with slurm | Introduction to Remote Computing" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="10 Executing large analyses on HPC clusters with slurm | Introduction to Remote Computing" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ngs-docs.github.io/2021-august-remote-computing/" />
  
  
  <meta name="github-repo" content="ngs-docs/2021-august-remote-computing/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10 Executing large analyses on HPC clusters with slurm | Introduction to Remote Computing" />
  
  
  

<meta name="author" content="C. Titus Brown, Saranya Canchi, Amanda Charbonneau, Marisa Lim, Abhijna Parigi, Pamela Reynolds, and Nick Ulle." />


<meta name="date" content="2021-08-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="automating-your-analyses-with-the-snakemake-workflow-system.html"/>
<link rel="next" href="making-use-of-on-demand-cloud-computers-from-amazon-web-services.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://datalab.ucdavis.edu/">
  <img src="https://datalab.ucdavis.edu/wp-content/uploads/2019/07/datalab-logo-full-color-rgb-1.png" style="height: 100%; width: 100%; object-fit: contain" />
</a></li>
<li><a href="https://www.nih-cfde.org/">
  <img src="cfde-logo.png" style="height: 60%; width: 60%; object-fit: contain" />
</a></li>
<li><a href="./" style="font-size: 18px">Introduction to Remote Computing (Pilot)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#introductory-skills"><i class="fa fa-check"></i>Introductory skills</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#intermediate-skills"><i class="fa fa-check"></i>Intermediate skills</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#advanced-skills"><i class="fa fa-check"></i>Advanced skills</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html"><i class="fa fa-check"></i><b>1</b> Introduction to the UNIX Command Line</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#introduction-to-unix"><i class="fa fa-check"></i><b>1.1</b> Introduction to UNIX</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#learning-goals"><i class="fa fa-check"></i><b>1.1.1</b> Learning Goals</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#navigation"><i class="fa fa-check"></i><b>1.2</b> Navigation</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#learning-goals-1"><i class="fa fa-check"></i><b>1.2.1</b> Learning Goals</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#viewing-searching"><i class="fa fa-check"></i><b>1.3</b> Viewing &amp; Searching</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#learning-goals-2"><i class="fa fa-check"></i><b>1.3.1</b> Learning Goals</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#file-manipulation"><i class="fa fa-check"></i><b>1.4</b> File Manipulation</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#learning-goals-3"><i class="fa fa-check"></i><b>1.4.1</b> Learning Goals</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#renaming-a-bunch-of-files"><i class="fa fa-check"></i><b>1.4.2</b> Renaming a bunch of files</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-the-unix-command-line.html"><a href="introduction-to-the-unix-command-line.html#some-final-notes"><i class="fa fa-check"></i><b>1.5</b> Some final notes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html"><i class="fa fa-check"></i><b>2</b> Creating and modifying text files on remote computers</a>
<ul>
<li class="chapter" data-level="2.1" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#text-files-vs-other-files"><i class="fa fa-check"></i><b>2.1</b> Text files vs other files</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#ok-ok-what-does-this-all-mean-in-practice"><i class="fa fa-check"></i><b>2.1.1</b> OK, OK, what does this all mean in practice?</a></li>
<li class="chapter" data-level="2.1.2" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#working-with-gzipped-files"><i class="fa fa-check"></i><b>2.1.2</b> Working with gzipped files</a></li>
<li class="chapter" data-level="2.1.3" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#digression-file-extensions-are-often-meaningful-but-dont-have-to-be"><i class="fa fa-check"></i><b>2.1.3</b> Digression: file extensions are often meaningful (but don’t have to be)</a></li>
<li class="chapter" data-level="2.1.4" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#lets-edit-this-file"><i class="fa fa-check"></i><b>2.1.4</b> Let’s edit this file!</a></li>
<li class="chapter" data-level="2.1.5" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#running-the-editor-and-exitingsaving"><i class="fa fa-check"></i><b>2.1.5</b> Running the editor and exiting/saving</a></li>
<li class="chapter" data-level="2.1.6" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#navigating-in-nano"><i class="fa fa-check"></i><b>2.1.6</b> Navigating in nano</a></li>
<li class="chapter" data-level="2.1.7" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#long-lines---note"><i class="fa fa-check"></i><b>2.1.7</b> Long lines - note!</a></li>
<li class="chapter" data-level="2.1.8" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#slightly-more-advanced-features"><i class="fa fa-check"></i><b>2.1.8</b> Slightly more advanced features</a></li>
<li class="chapter" data-level="2.1.9" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#getting-help"><i class="fa fa-check"></i><b>2.1.9</b> Getting help!</a></li>
<li class="chapter" data-level="2.1.10" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#challenges"><i class="fa fa-check"></i><b>2.1.10</b> Challenges:</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#big-powerful-editors"><i class="fa fa-check"></i><b>2.2</b> Big Powerful Editors</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#big-powerful-editor-1-vi"><i class="fa fa-check"></i><b>2.2.1</b> Big Powerful Editor 1: vi</a></li>
<li class="chapter" data-level="2.2.2" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#big-powerful-editor-2-emacs"><i class="fa fa-check"></i><b>2.2.2</b> Big Powerful Editor 2: emacs</a></li>
<li class="chapter" data-level="2.2.3" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#an-opinion"><i class="fa fa-check"></i><b>2.2.3</b> An opinion</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#remote-vs-local-and-why-editors"><i class="fa fa-check"></i><b>2.3</b> Remote vs local, and why editors?</a></li>
<li class="chapter" data-level="2.4" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#editors-that-run-locally-on-your-laptopdesktop"><i class="fa fa-check"></i><b>2.4</b> Editors that run locally on your laptop/desktop</a></li>
<li class="chapter" data-level="2.5" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#thinking-about-editors-as-a-means-to-an-end"><i class="fa fa-check"></i><b>2.5</b> Thinking about editors as a means to an end</a></li>
<li class="chapter" data-level="2.6" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#other-ways-to-create-edit-filter-and-modify-files"><i class="fa fa-check"></i><b>2.6</b> Other ways to create, edit, filter, and modify files</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#redirection-appending-and-piping."><i class="fa fa-check"></i><b>2.6.1</b> Redirection, appending, and piping.</a></li>
<li class="chapter" data-level="2.6.2" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#the-simplest-possible-editor---echo"><i class="fa fa-check"></i><b>2.6.2</b> The simplest possible “editor” - echo</a></li>
<li class="chapter" data-level="2.6.3" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#piping-and-filtering"><i class="fa fa-check"></i><b>2.6.3</b> Piping and filtering</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#working-with-csv-files"><i class="fa fa-check"></i><b>2.7</b> Working with CSV files</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#use-csvtk-when-working-with-csv-files-maybe."><i class="fa fa-check"></i><b>2.7.1</b> Use csvtk when working with CSV files, maybe.</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#a-quick-primer-on-compression."><i class="fa fa-check"></i><b>2.8</b> A quick primer on compression.</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#gzip-and-.gz-files."><i class="fa fa-check"></i><b>2.8.1</b> Gzip and <code>.gz</code> files.</a></li>
<li class="chapter" data-level="2.8.2" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#zip-and-compressing-multiple-files."><i class="fa fa-check"></i><b>2.8.2</b> zip and compressing <em>multiple</em> files.</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="creating-and-modifying-text-files-on-remote-computers.html"><a href="creating-and-modifying-text-files-on-remote-computers.html#concluding-thoughts"><i class="fa fa-check"></i><b>2.9</b> Concluding thoughts</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html"><i class="fa fa-check"></i><b>3</b> Connecting to remote computers with ssh</a>
<ul>
<li class="chapter" data-level="3.1" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#ssh-and-clients"><i class="fa fa-check"></i><b>3.1</b> SSH and Clients</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#some-security-thoughts"><i class="fa fa-check"></i><b>3.1.1</b> Some security thoughts</a></li>
<li class="chapter" data-level="3.1.2" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#ssh-as-a-protocol---many-clients"><i class="fa fa-check"></i><b>3.1.2</b> ssh as a protocol - many clients!</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#mac-os-x-using-the-terminal-program"><i class="fa fa-check"></i><b>3.2</b> Mac OS X: Using the Terminal program</a></li>
<li class="chapter" data-level="3.3" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#windows-connecting-to-remote-computers-with-mobaxterm"><i class="fa fa-check"></i><b>3.3</b> Windows: Connecting to remote computers with MobaXterm</a></li>
<li class="chapter" data-level="3.4" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#logging-out-and-logging-back-in."><i class="fa fa-check"></i><b>3.4</b> Logging out and logging back in.</a></li>
<li class="chapter" data-level="3.5" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#youre-logged-on-to-a-remote-computer.-now-what"><i class="fa fa-check"></i><b>3.5</b> You’re logged on to a remote computer. Now what?</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#welcome-to-your-account"><i class="fa fa-check"></i><b>3.5.1</b> Welcome to your account!</a></li>
<li class="chapter" data-level="3.5.2" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#loading-some-files-into-your-account"><i class="fa fa-check"></i><b>3.5.2</b> Loading some files into your account</a></li>
<li class="chapter" data-level="3.5.3" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#revisiting-file-and-path-manipulation"><i class="fa fa-check"></i><b>3.5.3</b> Revisiting file and path manipulation</a></li>
<li class="chapter" data-level="3.5.4" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#revisiting-file-editing"><i class="fa fa-check"></i><b>3.5.4</b> Revisiting file editing</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#copying-files-to-and-from-your-local-computer."><i class="fa fa-check"></i><b>3.6</b> Copying files to and from your local computer.</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#mac-os-x-copying-files-using-ssh."><i class="fa fa-check"></i><b>3.6.1</b> Mac OS X: Copying files using ssh.</a></li>
<li class="chapter" data-level="3.6.2" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#windows-copying-files-using-mobaxterm."><i class="fa fa-check"></i><b>3.6.2</b> Windows: Copying files using MobaXterm.</a></li>
<li class="chapter" data-level="3.6.3" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#view-and-change-the-file-you-just-downloaded"><i class="fa fa-check"></i><b>3.6.3</b> View and change the file you just downloaded</a></li>
<li class="chapter" data-level="3.6.4" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#copy-the-file-back-to-farm."><i class="fa fa-check"></i><b>3.6.4</b> Copy the file back to farm.</a></li>
<li class="chapter" data-level="3.6.5" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#digression-why-do-you-need-to-log-intolog-out-of-farm-on-mac-os-x"><i class="fa fa-check"></i><b>3.6.5</b> Digression: why do you need to log into/log out of farm on Mac OS X?</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#some-commands-are-available-others-are-not."><i class="fa fa-check"></i><b>3.7</b> Some commands are available! Others are not.</a></li>
<li class="chapter" data-level="3.8" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#summing-up-file-transfer---a-challenge"><i class="fa fa-check"></i><b>3.8</b> Summing up file transfer - a challenge!</a></li>
<li class="chapter" data-level="3.9" data-path="connecting-to-remote-computers-with-ssh.html"><a href="connecting-to-remote-computers-with-ssh.html#summing-things-up"><i class="fa fa-check"></i><b>3.9</b> Summing things up</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html"><i class="fa fa-check"></i><b>4</b> Running programs on remote computers and retrieving the results</a>
<ul>
<li class="chapter" data-level="4.1" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#using-ssh-privatepublic-key-pairs"><i class="fa fa-check"></i><b>4.1</b> Using SSH private/public key pairs</a></li>
<li class="chapter" data-level="4.2" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#mac-os-x-and-linux-using-ssh-private-keys-to-log-in"><i class="fa fa-check"></i><b>4.2</b> Mac OS X and Linux: Using ssh private keys to log in</a></li>
<li class="chapter" data-level="4.3" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#windowsmobaxterm-using-ssh-private-keys-to-log-in"><i class="fa fa-check"></i><b>4.3</b> Windows/MobaXterm: Using ssh private keys to log in</a></li>
<li class="chapter" data-level="4.4" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#some-tips-on-your-private-key"><i class="fa fa-check"></i><b>4.4</b> Some tips on your private key</a></li>
<li class="chapter" data-level="4.5" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#working-on-farm"><i class="fa fa-check"></i><b>4.5</b> Working on farm</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#first-download-some-files"><i class="fa fa-check"></i><b>4.5.1</b> First, download some files:</a></li>
<li class="chapter" data-level="4.5.2" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#configuring-your-account-on-login"><i class="fa fa-check"></i><b>4.5.2</b> Configuring your account on login</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#using-multiple-terminals"><i class="fa fa-check"></i><b>4.6</b> Using multiple terminals</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#who-am-i-and-where-am-i-running"><i class="fa fa-check"></i><b>4.6.1</b> Who am I and where am I running!?</a></li>
<li class="chapter" data-level="4.6.2" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#looking-at-whats-running"><i class="fa fa-check"></i><b>4.6.2</b> Looking at what’s running</a></li>
<li class="chapter" data-level="4.6.3" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#e-mailing-the-systems-administrators"><i class="fa fa-check"></i><b>4.6.3</b> E-mailing the systems administrators</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#file-systems-directories-and-shared-systems"><i class="fa fa-check"></i><b>4.7</b> File systems, directories, and shared systems</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#read-and-write-permissions-into-other-directories"><i class="fa fa-check"></i><b>4.7.1</b> Read and write permissions into other directories</a></li>
<li class="chapter" data-level="4.7.2" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#listing-directory-and-file-permissions"><i class="fa fa-check"></i><b>4.7.2</b> Listing directory and file permissions</a></li>
<li class="chapter" data-level="4.7.3" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#files-have-the-same-permission-options"><i class="fa fa-check"></i><b>4.7.3</b> Files have the same permission options</a></li>
<li class="chapter" data-level="4.7.4" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#how-do-groups-work"><i class="fa fa-check"></i><b>4.7.4</b> How do groups work?</a></li>
<li class="chapter" data-level="4.7.5" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#how-can-you-use-this"><i class="fa fa-check"></i><b>4.7.5</b> How can you use this?</a></li>
<li class="chapter" data-level="4.7.6" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#things-that-regular-users-cannot-do"><i class="fa fa-check"></i><b>4.7.6</b> Things that regular users cannot do</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#disk-space-file-size-and-temporary-files"><i class="fa fa-check"></i><b>4.8</b> Disk space, file size, and temporary files</a></li>
<li class="chapter" data-level="4.9" data-path="running-programs-on-remote-computers-and-retrieving-the-results.html"><a href="running-programs-on-remote-computers-and-retrieving-the-results.html#summing-things-up-1"><i class="fa fa-check"></i><b>4.9</b> Summing things up</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html"><i class="fa fa-check"></i><b>5</b> Installing software on remote computers with conda</a>
<ul>
<li class="chapter" data-level="5.1" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#why-is-software-installation-hard"><i class="fa fa-check"></i><b>5.1</b> Why is software installation hard?</a></li>
<li class="chapter" data-level="5.2" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#getting-started-with-conda"><i class="fa fa-check"></i><b>5.2</b> Getting started with conda</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#installing-conda"><i class="fa fa-check"></i><b>5.2.1</b> Installing conda</a></li>
<li class="chapter" data-level="5.2.2" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#log-into-farm"><i class="fa fa-check"></i><b>5.2.2</b> Log into farm</a></li>
<li class="chapter" data-level="5.2.3" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#creating-your-first-environment-installing-csvtk"><i class="fa fa-check"></i><b>5.2.3</b> Creating your first environment &amp; installing csvtk!</a></li>
<li class="chapter" data-level="5.2.4" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#installation"><i class="fa fa-check"></i><b>5.2.4</b> Installation!</a></li>
<li class="chapter" data-level="5.2.5" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#csvtk-in-a-bit-more-detail"><i class="fa fa-check"></i><b>5.2.5</b> csvtk in a bit more detail</a></li>
<li class="chapter" data-level="5.2.6" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#where-is-the-software-coming-from"><i class="fa fa-check"></i><b>5.2.6</b> Where is the software coming from!?</a></li>
<li class="chapter" data-level="5.2.7" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#digression-there-are-many-ways-to-install-software"><i class="fa fa-check"></i><b>5.2.7</b> Digression: there are many ways to install software!</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#installing-more-software-in-your-current-environment"><i class="fa fa-check"></i><b>5.3</b> Installing more software in your current environment</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#finding-and-specifying-versions"><i class="fa fa-check"></i><b>5.3.1</b> Finding and specifying versions</a></li>
<li class="chapter" data-level="5.3.2" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#making-and-using-environment-files"><i class="fa fa-check"></i><b>5.3.2</b> Making and using environment files</a></li>
<li class="chapter" data-level="5.3.3" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#updating-removing-etc-software"><i class="fa fa-check"></i><b>5.3.3</b> Updating, removing, etc software</a></li>
<li class="chapter" data-level="5.3.4" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#creating-multiple-environments"><i class="fa fa-check"></i><b>5.3.4</b> Creating multiple environments</a></li>
<li class="chapter" data-level="5.3.5" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#tech-interlude-what-is-conda-doing"><i class="fa fa-check"></i><b>5.3.5</b> Tech interlude: what is conda doing?</a></li>
<li class="chapter" data-level="5.3.6" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#challenges-with-using-one-big-environment"><i class="fa fa-check"></i><b>5.3.6</b> Challenges with using one big environment</a></li>
<li class="chapter" data-level="5.3.7" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#how-titus-uses-conda"><i class="fa fa-check"></i><b>5.3.7</b> How Titus uses conda</a></li>
<li class="chapter" data-level="5.3.8" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#finding-packages-within-conda"><i class="fa fa-check"></i><b>5.3.8</b> Finding packages within conda</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#using-the-bioconda-and-conda-forge-channels"><i class="fa fa-check"></i><b>5.4</b> Using the ‘bioconda’ and ‘conda-forge’ channels</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#mac-os-x-and-linux-but-not-windows"><i class="fa fa-check"></i><b>5.4.1</b> Mac OS X and Linux, but not Windows</a></li>
<li class="chapter" data-level="5.4.2" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#how-to-engage-with-conda-forge-and-bioconda"><i class="fa fa-check"></i><b>5.4.2</b> How to engage with conda-forge and bioconda</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#conda-and-data-science-r-and-python"><i class="fa fa-check"></i><b>5.5</b> Conda and data science: R and Python</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#conda-and-r"><i class="fa fa-check"></i><b>5.5.1</b> Conda and R</a></li>
<li class="chapter" data-level="5.5.2" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#conda-and-python"><i class="fa fa-check"></i><b>5.5.2</b> Conda and Python</a></li>
<li class="chapter" data-level="5.5.3" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#supporting-interactive-packages-rstudio-and-jupyterlab"><i class="fa fa-check"></i><b>5.5.3</b> Supporting interactive packages (RStudio and JupyterLab)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#tricky-things-to-think-about-with-conda"><i class="fa fa-check"></i><b>5.6</b> Tricky things to think about with conda</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#it-can-take-a-long-time-to-install-lots-of-software"><i class="fa fa-check"></i><b>5.6.1</b> It can take a long time to install lots of software</a></li>
<li class="chapter" data-level="5.6.2" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#explicit-package-listing"><i class="fa fa-check"></i><b>5.6.2</b> Explicit package listing</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#reference-list-of-conda-commands"><i class="fa fa-check"></i><b>5.7</b> Reference list of Conda Commands</a></li>
<li class="chapter" data-level="5.8" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#more-reading-on-conda"><i class="fa fa-check"></i><b>5.8</b> More Reading on Conda</a></li>
<li class="chapter" data-level="5.9" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#discussion-items"><i class="fa fa-check"></i><b>5.9</b> Discussion items:</a></li>
<li class="chapter" data-level="5.10" data-path="installing-software-on-remote-computers-with-conda.html"><a href="installing-software-on-remote-computers-with-conda.html#in-summary"><i class="fa fa-check"></i><b>5.10</b> In summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html"><i class="fa fa-check"></i><b>6</b> Structuring your projects for current and future you</a>
<ul>
<li class="chapter" data-level="6.1" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#learning-objectives"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#lesson-requirements"><i class="fa fa-check"></i><b>6.1.1</b> Lesson requirements</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#transferring-files-around-efficiently"><i class="fa fa-check"></i><b>6.2</b> Transferring files around efficiently</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#recursive-scp-with--r"><i class="fa fa-check"></i><b>6.2.1</b> recursive <code>scp</code> with <code>-r</code></a></li>
<li class="chapter" data-level="6.2.2" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#sftp"><i class="fa fa-check"></i><b>6.2.2</b> <code>sftp</code></a></li>
<li class="chapter" data-level="6.2.3" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#zip--r-to-create-collections-of-files"><i class="fa fa-check"></i><b>6.2.3</b> <code>zip -r</code> to create collections of files</a></li>
<li class="chapter" data-level="6.2.4" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#working-with-.tar.gz-files"><i class="fa fa-check"></i><b>6.2.4</b> Working with <code>.tar.gz</code> files</a></li>
<li class="chapter" data-level="6.2.5" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#probably-the-most-useful-advice-use-a-transfer-directory"><i class="fa fa-check"></i><b>6.2.5</b> Probably the most useful advice: use a transfer directory</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#retrieving-remote-files-from-web-sites"><i class="fa fa-check"></i><b>6.3</b> Retrieving remote files from Web sites</a></li>
<li class="chapter" data-level="6.4" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#dealing-with-files-some-recommendations"><i class="fa fa-check"></i><b>6.4</b> Dealing with files: some recommendations</a></li>
<li class="chapter" data-level="6.5" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#farm-vs-cloud"><i class="fa fa-check"></i><b>6.5</b> Farm vs cloud</a></li>
<li class="chapter" data-level="6.6" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#thinking-about-data-science-projects"><i class="fa fa-check"></i><b>6.6</b> Thinking about data science projects!</a></li>
<li class="chapter" data-level="6.7" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#one-example-a-rough-bioinformatics-workflow"><i class="fa fa-check"></i><b>6.7</b> One example: a rough bioinformatics workflow</a></li>
<li class="chapter" data-level="6.8" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#sending-and-receiving-data"><i class="fa fa-check"></i><b>6.8</b> Sending and Receiving Data</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#downloading-data---is-it-correct"><i class="fa fa-check"></i><b>6.8.1</b> Downloading data - is it correct?</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#storing-data"><i class="fa fa-check"></i><b>6.9</b> Storing data</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#bioinformatics-what-do-i-back-up"><i class="fa fa-check"></i><b>6.9.1</b> Bioinformatics: What do I back up?</a></li>
<li class="chapter" data-level="6.9.2" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#bioinformatics-how-big-should-i-expect-the-files-to-be"><i class="fa fa-check"></i><b>6.9.2</b> Bioinformatics: How big should I expect the files to be?</a></li>
<li class="chapter" data-level="6.9.3" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#how-often-should-i-backup-my-data"><i class="fa fa-check"></i><b>6.9.3</b> How often should I backup my data?</a></li>
<li class="chapter" data-level="6.9.4" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#where-do-i-back-up-my-data"><i class="fa fa-check"></i><b>6.9.4</b> Where do I back up my data?</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#where-do-i-work-with-large-amounts-of-data"><i class="fa fa-check"></i><b>6.10</b> Where do I work with large amounts of data?</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#high-performance-computing-clusters"><i class="fa fa-check"></i><b>6.10.1</b> High Performance Computing Clusters</a></li>
<li class="chapter" data-level="6.10.2" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#amazon-web-service"><i class="fa fa-check"></i><b>6.10.2</b> Amazon Web Service</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#setting-up-your-project"><i class="fa fa-check"></i><b>6.11</b> Setting up your project</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#things-to-think-about"><i class="fa fa-check"></i><b>6.11.1</b> Things to think about</a></li>
</ul></li>
<li class="chapter" data-level="6.12" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#naming-files"><i class="fa fa-check"></i><b>6.12</b> Naming files</a></li>
<li class="chapter" data-level="6.13" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#looking-forward-to-the-next-few-workshops-techniques-for-doing-data-science-on-remote-computers."><i class="fa fa-check"></i><b>6.13</b> Looking forward to the next few workshops: techniques for doing data science on remote computers.</a></li>
<li class="chapter" data-level="6.14" data-path="structuring-your-projects-for-current-and-future-you.html"><a href="structuring-your-projects-for-current-and-future-you.html#additional-resources"><i class="fa fa-check"></i><b>6.14</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><i class="fa fa-check"></i><b>7</b> Automating your analyses and executing long-running analyses on remote computers</a>
<ul>
<li class="chapter" data-level="7.1" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#what-is-a-script"><i class="fa fa-check"></i><b>7.1</b> What is a script?</a></li>
<li class="chapter" data-level="7.2" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#getting-started"><i class="fa fa-check"></i><b>7.2</b> Getting started</a></li>
<li class="chapter" data-level="7.3" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#automating-commands-by-putting-them-in-a-text-file"><i class="fa fa-check"></i><b>7.3</b> Automating commands by putting them in a text file</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#running-scripts-with-bash"><i class="fa fa-check"></i><b>7.3.1</b> Running scripts with <code>bash</code></a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#for-loops"><i class="fa fa-check"></i><b>7.4</b> <code>for</code> Loops</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#subsetting"><i class="fa fa-check"></i><b>7.4.1</b> Subsetting</a></li>
<li class="chapter" data-level="7.4.2" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#variables"><i class="fa fa-check"></i><b>7.4.2</b> Variables</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#troubleshooting-scripts"><i class="fa fa-check"></i><b>7.5</b> Troubleshooting scripts</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#practicing-set--e-in-bash-scripts"><i class="fa fa-check"></i><b>7.5.1</b> Practicing <code>set -e</code> in bash scripts</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#if-statements"><i class="fa fa-check"></i><b>7.6</b> If statements</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#running-scripts-in-a-loop"><i class="fa fa-check"></i><b>7.6.1</b> Running scripts in a loop</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#persistent-sessions-with-screen-and-tmux"><i class="fa fa-check"></i><b>7.7</b> Persistent sessions with screen and tmux</a></li>
<li class="chapter" data-level="7.8" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#concluding-thoughts-1"><i class="fa fa-check"></i><b>7.8</b> Concluding thoughts</a></li>
<li class="chapter" data-level="7.9" data-path="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html"><a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#appendix-exercise-answers"><i class="fa fa-check"></i><b>7.9</b> Appendix: exercise answers</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html"><i class="fa fa-check"></i><b>8</b> Keeping Track of Your Files with Version Control</a>
<ul>
<li class="chapter" data-level="8.1" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#learning-objectives-1"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#what-is-git"><i class="fa fa-check"></i><b>8.2</b> What is git?</a></li>
<li class="chapter" data-level="8.3" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#what-is-github"><i class="fa fa-check"></i><b>8.3</b> What is GitHub?</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#create-a-github-account"><i class="fa fa-check"></i><b>8.3.1</b> Create a GitHub Account</a></li>
<li class="chapter" data-level="8.3.2" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#create-a-new-repository"><i class="fa fa-check"></i><b>8.3.2</b> Create a New Repository</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#using-git"><i class="fa fa-check"></i><b>8.4</b> Using git</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#set-up-git-on-farm"><i class="fa fa-check"></i><b>8.4.1</b> Set up git on Farm</a></li>
<li class="chapter" data-level="8.4.2" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#optional-set-up-a-password-helper"><i class="fa fa-check"></i><b>8.4.2</b> Optional: Set up a Password Helper</a></li>
<li class="chapter" data-level="8.4.3" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#clone-the-repository"><i class="fa fa-check"></i><b>8.4.3</b> Clone the Repository</a></li>
<li class="chapter" data-level="8.4.4" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#edit-a-file"><i class="fa fa-check"></i><b>8.4.4</b> Edit a File</a></li>
<li class="chapter" data-level="8.4.5" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#commit-a-file"><i class="fa fa-check"></i><b>8.4.5</b> Commit a File</a></li>
<li class="chapter" data-level="8.4.6" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#view-the-repository-history-on-github"><i class="fa fa-check"></i><b>8.4.6</b> View the Repository History on GitHub</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#challenge-question-1"><i class="fa fa-check"></i><b>8.5</b> Challenge Question 1</a></li>
<li class="chapter" data-level="8.6" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#revisiting-the-workflow"><i class="fa fa-check"></i><b>8.6</b> Revisiting the Workflow</a></li>
<li class="chapter" data-level="8.7" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#undoing-changes"><i class="fa fa-check"></i><b>8.7</b> Undoing Changes</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#restoring-a-file"><i class="fa fa-check"></i><b>8.7.1</b> Restoring a File</a></li>
<li class="chapter" data-level="8.7.2" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#reverting-a-commit"><i class="fa fa-check"></i><b>8.7.2</b> Reverting a Commit</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#challenge-question-2"><i class="fa fa-check"></i><b>8.8</b> Challenge Question 2</a></li>
<li class="chapter" data-level="8.9" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#working-collaboratively"><i class="fa fa-check"></i><b>8.9</b> Working Collaboratively</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#editing-on-github"><i class="fa fa-check"></i><b>8.9.1</b> Editing on GitHub</a></li>
<li class="chapter" data-level="8.9.2" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#merge-conflicts"><i class="fa fa-check"></i><b>8.9.2</b> Merge Conflicts</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#challenge-question-3"><i class="fa fa-check"></i><b>8.10</b> Challenge Question 3</a></li>
<li class="chapter" data-level="8.11" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#odds-and-ends"><i class="fa fa-check"></i><b>8.11</b> Odds and Ends</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#ignoring-files-with-.gitignore"><i class="fa fa-check"></i><b>8.11.1</b> Ignoring Files with <code>.gitignore</code></a></li>
<li class="chapter" data-level="8.11.2" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#setting-up-a-repository-without-github"><i class="fa fa-check"></i><b>8.11.2</b> Setting up a Repository without GitHub</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="keeping-track-of-your-files-with-version-control.html"><a href="keeping-track-of-your-files-with-version-control.html#additional-resources-1"><i class="fa fa-check"></i><b>8.12</b> Additional Resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html"><i class="fa fa-check"></i><b>9</b> Automating your analyses with the snakemake workflow system</a>
<ul>
<li class="chapter" data-level="9.1" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#what-is-a-workflow-and-why-use-one"><i class="fa fa-check"></i><b>9.1</b> What is a workflow and why use one?</a></li>
<li class="chapter" data-level="9.2" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#snakemake-a-workflow-management-system"><i class="fa fa-check"></i><b>9.2</b> Snakemake: A workflow management system</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#fun-fact"><i class="fa fa-check"></i><b>9.2.1</b> Fun fact</a></li>
<li class="chapter" data-level="9.2.2" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#the-snakefile"><i class="fa fa-check"></i><b>9.2.2</b> The Snakefile</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#getting-started---logging-into-farm"><i class="fa fa-check"></i><b>9.3</b> Getting started - logging into farm!</a></li>
<li class="chapter" data-level="9.4" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#installing-snakemake"><i class="fa fa-check"></i><b>9.4</b> Installing snakemake</a></li>
<li class="chapter" data-level="9.5" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#more-setup"><i class="fa fa-check"></i><b>9.5</b> More setup</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#create-a-working-directory"><i class="fa fa-check"></i><b>9.5.1</b> Create a working directory</a></li>
<li class="chapter" data-level="9.5.2" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#download-some-data"><i class="fa fa-check"></i><b>9.5.2</b> Download some data</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#rna-seq-workflow-we-will-automate"><i class="fa fa-check"></i><b>9.6</b> RNA-Seq workflow we will automate</a></li>
<li class="chapter" data-level="9.7" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#first-step-quality-control-with-fastqc"><i class="fa fa-check"></i><b>9.7</b> First step: quality control with FASTQC</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#create-a-snakefile"><i class="fa fa-check"></i><b>9.7.1</b> Create a Snakefile</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#some-features-of-workflows"><i class="fa fa-check"></i><b>9.8</b> Some features of workflows</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#what-are-these-flags--p--j"><i class="fa fa-check"></i><b>9.8.1</b> What are these flags (<code>-p</code>, <code>-j</code>)?</a></li>
<li class="chapter" data-level="9.8.2" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#when-you-run-snakemake-by-default-it-runs-the-first-rule."><i class="fa fa-check"></i><b>9.8.2</b> When you run snakemake, by default, it runs the first rule.</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#making-the-rules-more-generic"><i class="fa fa-check"></i><b>9.9</b> Making the rules more generic</a></li>
<li class="chapter" data-level="9.10" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#wildcards"><i class="fa fa-check"></i><b>9.10</b> Wildcards</a></li>
<li class="chapter" data-level="9.11" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#adding-more-rules"><i class="fa fa-check"></i><b>9.11</b> Adding more rules</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#downloading-the-reference-genome"><i class="fa fa-check"></i><b>9.11.1</b> Downloading the reference genome</a></li>
<li class="chapter" data-level="9.11.2" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#add-the-index-genome-command"><i class="fa fa-check"></i><b>9.11.2</b> Add the index genome command:</a></li>
<li class="chapter" data-level="9.11.3" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#running-salmon-quant"><i class="fa fa-check"></i><b>9.11.3</b> Running Salmon quant</a></li>
<li class="chapter" data-level="9.11.4" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#one-version-of-the-final-snakefile"><i class="fa fa-check"></i><b>9.11.4</b> One version of the final Snakefile</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#titus-version-of-the-final-snakefile-as-created-during-the-workshop"><i class="fa fa-check"></i><b>9.12</b> Titus’ version of the final snakefile as created during the workshop</a></li>
<li class="chapter" data-level="9.13" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#random-aside---dry-run-or--n"><i class="fa fa-check"></i><b>9.13</b> Random aside: <code>--dry-run</code> or <code>-n</code></a></li>
<li class="chapter" data-level="9.14" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#advanced-features"><i class="fa fa-check"></i><b>9.14</b> Advanced features</a>
<ul>
<li class="chapter" data-level="9.14.1" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#rule-specific-conda-environments-with-conda-and---use-conda"><i class="fa fa-check"></i><b>9.14.1</b> Rule-specific conda environments with conda: and <code>--use-conda</code></a></li>
<li class="chapter" data-level="9.14.2" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#parallelizing-snakemake--j"><i class="fa fa-check"></i><b>9.14.2</b> parallelizing snakemake: -j</a></li>
</ul></li>
<li class="chapter" data-level="9.15" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#practical-advice-how-to-build-your-workflow"><i class="fa fa-check"></i><b>9.15</b> Practical advice: How to build your workflow</a>
<ul>
<li class="chapter" data-level="9.15.1" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#approach-1-write-down-your-shell-commands"><i class="fa fa-check"></i><b>9.15.1</b> Approach 1: write down your shell commands</a></li>
<li class="chapter" data-level="9.15.2" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#approach-2-automate-one-step-that-you-run-a-lot"><i class="fa fa-check"></i><b>9.15.2</b> Approach 2: automate one step that you run a lot</a></li>
</ul></li>
<li class="chapter" data-level="9.16" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#summary-of-what-we-did-today."><i class="fa fa-check"></i><b>9.16</b> Summary of what we did today.</a></li>
<li class="chapter" data-level="9.17" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#more-snakemake-resources"><i class="fa fa-check"></i><b>9.17</b> More Snakemake resources</a></li>
<li class="chapter" data-level="9.18" data-path="automating-your-analyses-with-the-snakemake-workflow-system.html"><a href="automating-your-analyses-with-the-snakemake-workflow-system.html#a-quick-checklist"><i class="fa fa-check"></i><b>9.18</b> A quick checklist:</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html"><i class="fa fa-check"></i><b>10</b> Executing large analyses on HPC clusters with slurm</a>
<ul>
<li class="chapter" data-level="10.1" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#what-is-a-cluster"><i class="fa fa-check"></i><b>10.1</b> What is a cluster?</a></li>
<li class="chapter" data-level="10.2" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#how-do-clusters-work"><i class="fa fa-check"></i><b>10.2</b> How do clusters work?</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#job-schedulers"><i class="fa fa-check"></i><b>10.2.1</b> Job Schedulers</a></li>
<li class="chapter" data-level="10.2.2" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#either-run-an-interactive-session-with-srun"><i class="fa fa-check"></i><b>10.2.2</b> EITHER: run an interactive session with <code>srun</code></a></li>
<li class="chapter" data-level="10.2.3" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#or-submit-batch-scripts-with-sbatch"><i class="fa fa-check"></i><b>10.2.3</b> OR: Submit batch scripts with <code>sbatch</code></a></li>
<li class="chapter" data-level="10.2.4" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#flags-to-use-when-submitting-jobs-with-sbatch-or-srun"><i class="fa fa-check"></i><b>10.2.4</b> Flags to use when submitting jobs with sbatch or srun</a></li>
<li class="chapter" data-level="10.2.5" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#repeatability-through-sbatch-variables-in-shell-scripts"><i class="fa fa-check"></i><b>10.2.5</b> Repeatability through SBATCH variables in shell scripts</a></li>
<li class="chapter" data-level="10.2.6" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#reprise-running-helloworld.sh-via-srun"><i class="fa fa-check"></i><b>10.2.6</b> Reprise: running <code>HelloWorld.sh</code> via srun</a></li>
<li class="chapter" data-level="10.2.7" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#choosing-between-srun-and-sbatch"><i class="fa fa-check"></i><b>10.2.7</b> Choosing between <code>srun</code> and <code>sbatch</code></a></li>
<li class="chapter" data-level="10.2.8" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#a-stock-sbatch-script-that-includes-activating-a-conda-environment"><i class="fa fa-check"></i><b>10.2.8</b> A stock sbatch script that includes activating a conda environment</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#some-useful-tips-and-tricks-for-happy-slurm-ing"><i class="fa fa-check"></i><b>10.3</b> Some useful tips and tricks for happy slurm-ing</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#trick-1-running-srun-inside-of-a-screen."><i class="fa fa-check"></i><b>10.3.1</b> Trick 1: running <code>srun</code> inside of a screen.</a></li>
<li class="chapter" data-level="10.3.2" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#trick-2-running-snakemake-inside-of-an-sbatch-script."><i class="fa fa-check"></i><b>10.3.2</b> Trick 2: running snakemake inside of an sbatch script.</a></li>
<li class="chapter" data-level="10.3.3" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#monitoring-your-jobs-with-squeue"><i class="fa fa-check"></i><b>10.3.3</b> Monitoring your jobs with <code>squeue</code></a></li>
<li class="chapter" data-level="10.3.4" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#canceling-your-jobs-with-scancel"><i class="fa fa-check"></i><b>10.3.4</b> Canceling your jobs with <code>scancel</code></a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#more-on-resources-and-queues-and-sharing"><i class="fa fa-check"></i><b>10.4</b> More on resources and queues and sharing</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#measuring-your-resource-usage"><i class="fa fa-check"></i><b>10.4.1</b> Measuring your resource usage</a></li>
<li class="chapter" data-level="10.4.2" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#nodes-vs-cpus-vs-tasks"><i class="fa fa-check"></i><b>10.4.2</b> Nodes vs CPUs vs tasks</a></li>
<li class="chapter" data-level="10.4.3" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#partitions"><i class="fa fa-check"></i><b>10.4.3</b> Partitions</a></li>
<li class="chapter" data-level="10.4.4" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#how-to-share-within-your-group"><i class="fa fa-check"></i><b>10.4.4</b> How to share within your group</a></li>
<li class="chapter" data-level="10.4.5" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#how-can-you-get-an-account-on-your-hpc"><i class="fa fa-check"></i><b>10.4.5</b> How can you get an account on your HPC?</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#what-weve-shown-you-today."><i class="fa fa-check"></i><b>10.5</b> What we’ve shown you today.</a></li>
<li class="chapter" data-level="10.6" data-path="executing-large-analyses-on-hpc-clusters-with-slurm.html"><a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#some-final-thoughts-before-departing-farm-and-moving-into-the-cloud."><i class="fa fa-check"></i><b>10.6</b> Some final thoughts before departing farm and moving into the cloud.</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="making-use-of-on-demand-cloud-computers-from-amazon-web-services.html"><a href="making-use-of-on-demand-cloud-computers-from-amazon-web-services.html"><i class="fa fa-check"></i><b>11</b> Making use of on-demand “cloud” computers from Amazon Web Services</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#workshop-protocol"><i class="fa fa-check"></i>Workshop Protocol</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Remote Computing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="executing-large-analyses-on-hpc-clusters-with-slurm" class="section level1" number="10">
<h1><span class="header-section-number">10</span> Executing large analyses on HPC clusters with slurm</h1>
<p>This two hour workshop will introduce attendees to the slurm system
for using, queuing and scheduling analyses on high performance compute
clusters. We will also cover cluster computing concepts and talk about
how to estimate the compute resources you need and measure how much
you’ve used.</p>
<p>This lesson was originally written by Shannon Joslin for GGG 298 at UC Davis (<a href="https://github.com/ngs-docs/2021-GGG298/blob/latest/Week9-Slurm_and_Farm_cluster_for_doing_analysis/README.md">see original lesson</a>).</p>
<div id="what-is-a-cluster" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> What is a cluster?</h2>
<p>A cluster can be thought of as a group of computers which work
together to allow you to perform memory intensive functions. Clusters
are accessed by logging onto one computer (<strong>head node</strong>) and
resources (other computers) are acquired by asking for resources from
job schedulers.</p>
<p><img src="slurm-cluster.png" /></p>
<p>Image modified from <a href="http://www.vrlab.umu.se/documentation/guides/beginner-guide">vrlab</a></p>
</div>
<div id="how-do-clusters-work" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> How do clusters work?</h2>
<div id="job-schedulers" class="section level3" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> Job Schedulers</h3>
<p>In order to carry out commands that are memory intensive we need to
use auxiliary computers that will not affect the login/head
node, which is usually shared by many people.</p>
<p><strong>NOTE:</strong> sometimes merely copying large files is memory
intensive enough that we will need to (or should) use computers other
than the head node!</p>
<p>To request resources to run our scripts we use <em>job
schedulers</em>. Job schedulers handle how to allocate the compute
cluster’s resources to batch job scripts submitted by users.</p>
<p>There are a number of different flavors of job schedulers. The job
scheduler you will be submitting jobs to is specific to the cluster
you are using at your institution but they all have the following
general structure:</p>
<p><img src="slurm-scheduler.png" /></p>
<p>The job scheduler evaluates when resources will be dedicated to a job based on the:</p>
<ul>
<li>partition &amp; priority (<code>-p</code>)</li>
<li>how much of the group’s resources are already being used</li>
<li>requested wall time (<code>-t</code>)</li>
<li>requested resources
<ul>
<li>memory (<code>--mem</code>)</li>
<li>CPUs (<code>-c</code>)</li>
</ul></li>
</ul>
<p>The <a href="https://slurm.schedmd.com/documentation.html">Slurm workload
manager</a> is an open
source workload manager that is commonly used on compute clusters
(both farm and barbera at UC Davis use Slurm). It handles allocating
resources requested by batch scripts.</p>
<p>There are <strong>two</strong> main ways you can request resources using Slurm:</p>
</div>
<div id="either-run-an-interactive-session-with-srun" class="section level3" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> EITHER: run an interactive session with <code>srun</code></h3>
<p>Interactive sessions allow you to work on computers that aren’t the
login/head node. Essentially you can do everything you’ve done at the
command line interface on the compute cluster. This is
really powerful for doing memory intensive commands that you may not
need to keep track of. However, with this power comes a great danger!</p>
<p><em>Why is it dangerous?</em> This is an interactive session, so the commands
you run will not be saved in scripts anywhere. So, if you wanted to go
back and recreate an analysis, you won’t know what you’ve run, how
you’ve run it or which versions of software you used.</p>
<p>To request and launch a basic interactive session that will last for
10 minutes, use the following:</p>
<pre><code>srun --partition high2 --time=00:10:00 --pty /bin/bash</code></pre>
<p>If successful, you should see something like:</p>
<blockquote>
<pre><code>srun: job 37969118 queued and waiting for resources
srun: job 37969118 has been allocated resources</code></pre>
</blockquote>
<p>You’ll also see that your prompt changes.</p>
<blockquote>
<pre><code>(base) datalab-09@c6-92:~$</code></pre>
</blockquote>
<p>This is because you’re no longer on farm - you’re in a shell on one of
the cluster nodes. (Here, <code>c6-92</code> is the hostname of one of the
cluster nodes!)</p>
<p>OK, so what’s going on here?</p>
<p>In order to handle jobs, Slurm needs to know <strong>where to run it</strong>, and
the maximum amount of <strong>walltime</strong> your job will run. This is so that
it can properly allocate a computer to handle your job and (try to)
predict when those resources will be available for others.</p>
<p>With the <code>--partition</code> flag, you’re telling srun to use a particular
<em>partition</em>, or subset of nodes, that is for high priority jobs -
we’ll talk more about this below!</p>
<p>The <code>--time</code> flag specifies the walltime you’re asking for. Walltime
is literally “the time shown on the clock on the wall”, and can be
measured as the maximum expected amount of time from the start of your
job to the end of the job.</p>
<p>Pay close attention to the time you give to yourself here! Slurm will
terminate the session immediately at the end of the allotted
time. Sadly, it doesn’t care (or know) if you are 99.99% of the way
through your analysis :/</p>
<p>The default resources that you’re allocated are:</p>
<ul>
<li>2 GB of RAM</li>
<li>1 CPU</li>
</ul>
<p>and we’ll show you how to figure that out for yourself, below, using
<code>squeue</code>.</p>
<p>You can request more or different resources by using the following flags:</p>
<ul>
<li><code>--mem=&lt;number&gt;Gb</code> = request a certain amount of memory</li>
<li><code>-c &lt;number&gt;</code> = request a certain number of CPUs</li>
</ul>
<p>Here, the <code>-c</code> flag is the same number you would use for <code>snakemake -j</code> to run many things in parallel; see <a href="automating-your-analyses-with-the-snakemake-workflow-system.html#automating-your-analyses-with-the-snakemake-workflow-system">Automating your analyses with
the snakemake workflow system</a> for the snakemake lesson. (We’ll show
you how to run snakemake inside of slurm below!)</p>
<p><strong>If your prompt doesn’t have <code>farm</code> in it</strong> - that is, if you’re logged into
a different computer in an <code>srun</code> session - you should type <code>exit</code> now
to get back to the head node:</p>
<pre><code>exit</code></pre>
<p>This will exit the shell. If you <em>are</em> on farm head node already, this
will just log you out of your ssh session and you should log back in
;).</p>
<p>CHALLENGE: on the farm head node, set yourself up for a 5 second session
using srun. What happens when the five seconds are up?</p>
</div>
<div id="or-submit-batch-scripts-with-sbatch" class="section level3" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> OR: Submit batch scripts with <code>sbatch</code></h3>
<p>The alternative to <code>srun</code> is <code>sbatch</code>, which is my preferred way (and
the suggested way!) to run batch job scripts, for several reasons.</p>
<p>Batch job scripts (also known as job scripts) are scripts that contain
<code>#! /bin/bash</code> at the beginning of each script and are submitted to
the slurm workload manager by using <code>sbatch</code>. They are (mostly) just
shell scripts, with a few exceptions. We can use the same commands
that we would use at the command line within our <code>sbatch</code> scripts.</p>
<p>(For more info on bash scripts, see <a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#automating-your-analyses-and-executing-long-running-analyses-on-remote-computers">Automating your analyses and
executing long-running analyses on remote computers</a>.)</p>
<p>First, to try out <code>sbatch</code> let’s create a script called
<code>HelloWorld.sh</code>.</p>
<pre><code>mkdir -p ~/slurm-lesson
cd ~/slurm-lesson
nano HelloWorld.sh</code></pre>
<p>Then copy and paste the following:</p>
<pre><code>#! /bin/bash

echo Hello World
sleep 15
date</code></pre>
<p>Then exit nano with <kbd>Ctrl+X</kbd></p>
<p>Try running it:</p>
<pre><code>bash HelloWorld.sh</code></pre>
<p>what does it do?</p>
<hr />
<p>We can submit this script to <strong>Slurm</strong> with the <code>sbatch</code> command.</p>
<pre><code>sbatch HelloWorld.sh</code></pre>
<p>but we receive an error message…</p>
<pre><code>sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified</code></pre>
<p>As with <code>srun</code>, above, we must tell Slurm how much time to allow our
submitted script by using the <code>-t/--time</code> flag, and what queue to run
it on with <code>-p/--partition</code>. Let’s tell Slurm that our job <em>shouldn’t</em>
take longer than 5 minutes (note: the format is <code>dd-hh:mm:ss</code>, or
<code>days-hours:minutes:seconds</code>), and to use the <code>high2</code> partition of the
cluster.</p>
<pre><code>sbatch -t 00-00:05:00 -p high2 HelloWorld.sh</code></pre>
<p>You will see your job was successfully submitted and will be given an
associated Job ID number:</p>
<blockquote>
<pre><code>Submitted batch job 15219016</code></pre>
</blockquote>
<p>but with a different number. This is a unique job ID that you can use
to monitor (with <code>squeue</code>) and cancel your job (with <code>scancel</code>).
See <a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#monitoring-your-jobs-with-squeue">Monitoring your jobs with <code>squeue</code></a>, below.</p>
</div>
<div id="flags-to-use-when-submitting-jobs-with-sbatch-or-srun" class="section level3" number="10.2.4">
<h3><span class="header-section-number">10.2.4</span> Flags to use when submitting jobs with sbatch or srun</h3>
<p>We can use a number of different flags to specify resources we want
from Slurm (we’ll cover how to measure these in <a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#measuring-your-resource-usage">Measuring your
resource usage</a>).</p>
<ul>
<li>the <strong>partition</strong> we would like to use for our job –
this will also dictate the <em>priority</em> with which our job is run. This is
heavily cluster and account dependent; on farm, your datalab-XX accounts
have access to <code>high2</code>, <code>med2</code>, and <code>low2</code>, for example, which let you run
on CPU-intensive nodes at high, medium, and low priority. See <a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#partitions">Partitions</a>, below.</li>
<li>the <strong>memory</strong> required to run our job. We can request a specified amount of memory with the following flag: <code>--mem=&lt;number&gt;Gb</code></li>
<li>we can have slurm <strong>e-mail</strong> us updates about our job, such as when it starts(<code>BEGIN</code>), ends(<code>END</code>), if it fails(<code>FAIL</code>) or all of the above (<code>ALL</code>). There are many other mail-type arguments: REQUEUE, ALL, TIME_LIMIT, TIME_LIMIT_90 (reached 90 percent of time limit), TIME_LIMIT_80 (reached 80 percent of time limit), TIME_LIMIT_50 (reached 50 percent of time limit) and ARRAY_TASKS. We can request slurm emails us with the following flags: <code>--mail-user=&lt;your_email&gt; --mail-type=&lt;argument&gt;</code></li>
<li>we can also give jobs specific <strong>names</strong>. To name your job use: <code>-J &lt;job_name&gt;</code> Be careful, as there is a limit to the number of characters your job name can be.</li>
<li>slurm automatically records <strong>stdout output</strong> where all of the output from commands run from the script are printed to. These will take the form as <code>slurm-12345.out</code> where 12345 is an identifying number (the job ID, by default!) slurm assigns to the file. We can change this to any output file name we want. To specify the name of your output file use <code>-o &lt;file_name&gt;.out</code></li>
<li>slurm can record <strong>stderr output</strong>, where all of the errors from the script are printed to. We can ask slurm to create err files and name them with <code>-e &lt;file_name&gt;.err</code></li>
</ul>
<p>If we were being mean to ourselves we would write these out at the
command line each time we submitted a job to slurm with <code>sbatch</code>. It
would look something like this:</p>
<pre><code>sbatch --time=01-02:03:04 -p high2 --mem=4Gb --mail-user=&lt;your_email&gt; --mail-type=ALL -J &lt;job_name&gt; -o &lt;file_name&gt;.out -e &lt;file_name&gt;.err</code></pre>
<p>(We would need to switch out all of the <code>&lt;text&gt;</code> with parameters
specific to our preference, but hopefully you get the gist.)</p>
<p>But we can make this much easier on ourselves! Typing all of the
parameters out on the command line every time we want to submit a
batch script is annoying and it also doesn’t allow us to record what
parameters we used easily. We can instead put the parameters to run
each job in the script we submit to slurm!</p>
<p>This also has the advantage of supporting repeatability!</p>
</div>
<div id="repeatability-through-sbatch-variables-in-shell-scripts" class="section level3" number="10.2.5">
<h3><span class="header-section-number">10.2.5</span> Repeatability through SBATCH variables in shell scripts</h3>
<p>One of the most important things in computational science is
repeatability - can I run <em>exactly</em> the same thing today as I did
yesterday? You’d think this would be straightforward, but it is
exceptionally easy to run a series of command on data, leave the data
for a few months (or years) and come back to the data and have no clue
how you went from point A to point Z.</p>
<p>(Just to be clear, this is bad. :)</p>
<p>Let’s say we lost everything except our backed up raw data and we
needed to recreate an analysis. In the worst case, where the commands
used to carry out the experiment were not saved, we would have to
figure out all of the commands with only a vague memory of the steps
we took to get results. It is hard, if not impossible to recreate an
analysis with exactly the same string of commands and parameters. So,
we should think about documenting things as we go.</p>
<p>In the best case (of this terrible scenario) we would have a script to
recreate our analysis! So, we can make this easy for our <em>future</em>
forgetful-selves and put all of the flags and commands we submit to
Slurm INSIDE our batch scripts!</p>
<p>We can do this by adding <strong>#SBATCH</strong> lines of code after the sha-bang
line (<code>#! /bin/bash</code>) in our script.</p>
<p>Let’s save the parameters we used to run <code>HelloWorld.sh</code> within the
batch script instead of specifying them on the command line.</p>
<p>Modify your HelloWorld.sh script to look like the following:</p>
<pre><code>#! /bin/bash
#
#SBATCH --mail-user=&lt;email&gt;@ucdavis.edu         # YOUR EMAIL ADDRESS
#SBATCH --mail-type=ALL                         # NOTIFICATIONS OF SLURM JOB STATUS - ALL, NONE, BEGIN, END, FAIL, REQUEUE
#SBATCH -J HelloWorld                           # JOB ID
#SBATCH -e HelloWorld.j%j.err                   # STANDARD ERROR FILE TO WRITE TO
#SBATCH -o HelloWorld.j%j.out                   # STANDARD OUTPUT FILE TO WRITE TO
#SBATCH -c 1                                    # NUMBER OF PROCESSORS PER TASK
#SBATCH --mem=1Gb                               # MEMORY POOL TO ALL CORES
#SBATCH --time=00-00:05:00                      # REQUESTED WALL TIME
#SBATCH -p high2                                # PARTITION TO SUBMIT TO

echo Hello World
sleep 15
date</code></pre>
<p>(<strong>Make sure to replace your <code>&lt;email&gt;</code> with your UC Davis email address.</strong>)</p>
<p>Then submit your script:</p>
<pre><code>sbatch HelloWorld.sh</code></pre>
<p>Once our scripts start running, we should see the following files in
our current directory: <code>HelloWorld.j#######.err</code> and
<code>HelloWorld.j#######.out</code>. These are the recorded outputs from running
your batch job with slurm!</p>
</div>
<div id="reprise-running-helloworld.sh-via-srun" class="section level3" number="10.2.6">
<h3><span class="header-section-number">10.2.6</span> Reprise: running <code>HelloWorld.sh</code> via srun</h3>
<p>Of course, even with all the SBATCH stuff in the script, it’s still just
a shell script that you can run at the command line; the only command that
pays attention to the <code>#SBATCH</code> lines is <code>sbatch</code> itself!</p>
<p>This is useful for debugging. Sometimes you’ll have to debug a script
that isn’t working the way you want it to, and you’ll want to do this
interactively. If you can use the head node for this, great - but sometimes
the problem is that the script uses resources that aren’t available for the
head node, OR (even worse) that the script runs fine on the head node, but
NOT via sbatch.</p>
<p>In this case, you can use <code>srun</code> to allocate yourself a node, and then
go run the script yourself.</p>
<p>CHALLENGE: Use <code>srun</code> to allocate a node, and then run <code>HelloWorld.sh</code>.</p>
<p>Question: do you get the e-mails and the output files as with sbatch?</p>
<p>(No, because when you’re running the script via bash inside an <code>srun</code>,
slurm doesn’t know it’s a special script.)</p>
</div>
<div id="choosing-between-srun-and-sbatch" class="section level3" number="10.2.7">
<h3><span class="header-section-number">10.2.7</span> Choosing between <code>srun</code> and <code>sbatch</code></h3>
<p>I use <code>srun</code> when I want to explore or debug something, or need an
interactive prompt. Sometimes I’ll use it when I want to run something
at a high priority and don’t want to have to write a batch script, but
I <em>almost always</em> regret it when I do this. (Be better than me!)</p>
<p>I almost always prefer <code>sbatch</code>. There are a bunch of reasons -</p>
<ul>
<li>the script is a text file, so I can correct it if I get something wrong!</li>
<li>the script specifies the resources at the top, so I can edit those easily!</li>
<li>I can comment the script so I can understand it later.</li>
<li>I can use version control to track changes to my sbatch scripts (see <a href="keeping-track-of-your-files-with-version-control.html#keeping-track-of-your-files-with-version-control">Keeping Track of Your Files with Version Control</a>)</li>
<li>I can run one (or a dozen) sbatch scripts at various priorities, and can be notified by e-mail when they’re done. This lets me walk away from the computer :)</li>
</ul>
</div>
<div id="a-stock-sbatch-script-that-includes-activating-a-conda-environment" class="section level3" number="10.2.8">
<h3><span class="header-section-number">10.2.8</span> A stock sbatch script that includes activating a conda environment</h3>
<p>Here’s the sbatch script I usually start with. It has a few nice
features:</p>
<ul>
<li>it lists the parameters that I usually end up modifying (<code>-c</code>, <code>-t</code>, <code>--mem</code>)</li>
<li>it supports conda environment activation (see <a href="installing-software-on-remote-computers-with-conda.html#installing-software-on-remote-computers-with-conda">Installing software on remote computers with conda</a>)</li>
<li>it prints out the resources I actually used at the end! (See <a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#measuring-your-resource-usage">Measuring your resource usage</a> below)</li>
</ul>
<pre><code>#!/bin/bash -login
#SBATCH -p med2                # use &#39;med2&#39; partition for medium priority
#SBATCH -J myjob               # name for job
#SBATCH -c 1                   # 1 core
#SBATCH -t 1:00:00             # ask for an hour, max
#SBATCH --mem=2000             # memory (2000 mb = 2gb)
#SBATCH --mail-type=ALL
#SBATCH --mail-user=&lt;email&gt;@ucdavis.edu

# initialize conda
. ~/miniconda3/etc/profile.d/conda.sh

# activate your desired conda environment
conda activate base

# fail on weird errors
set -e
set -x

### YOUR COMMANDS GO HERE ###
# for example,
sleep 15
### YOUR COMMANDS GO HERE ###

# Print out values of the current jobs SLURM environment variables
env | grep SLURM

# Print out final statistics about resource use before job exits
scontrol show job ${SLURM_JOB_ID}

sstat --format &#39;JobID,MaxRSS,AveCPU&#39; -P ${SLURM_JOB_ID}.batch</code></pre>
<p>We’ll talk a bit more about the choices made in this script,
below, when we talk about choosing your CPU and memory.
See <a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#measuring-your-resource-usage">Measuring your resource usage</a>, below.</p>
<p>But first, let’s cover…</p>
</div>
</div>
<div id="some-useful-tips-and-tricks-for-happy-slurm-ing" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> Some useful tips and tricks for happy slurm-ing</h2>
<div id="trick-1-running-srun-inside-of-a-screen." class="section level3" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Trick 1: running <code>srun</code> inside of a screen.</h3>
<p>Back in <a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#automating-your-analyses-and-executing-long-running-analyses-on-remote-computers">Automating your analyses and executing long-running analyses on remote computers</a>, we introduced you to <a href="automating-your-analyses-and-executing-long-running-analyses-on-remote-computers.html#persistent-sessions-with-screen-and-tmux">Persistent sessions with screen and tmux</a>.</p>
<p>If you are using srun to run commands, it is just like any other interactive
shell - if you close your laptop, or your network is disconnected, you’ll
terminate the shell.</p>
<p>So I often use <code>screen</code> to make my <code>srun</code> sessions resilient to laptop closure
and shell termination.</p>
<p>There’s one key trick here: run <code>screen</code> <em>first</em>, then run <code>srun</code>.</p>
<p>(I’ll show a demo, you don’t need to follow along - just know that this
is a possibility.)</p>
</div>
<div id="trick-2-running-snakemake-inside-of-an-sbatch-script." class="section level3" number="10.3.2">
<h3><span class="header-section-number">10.3.2</span> Trick 2: running snakemake inside of an sbatch script.</h3>
<p>In our previous workshop, we introduced you to <a href="automating-your-analyses-with-the-snakemake-workflow-system.html#automating-your-analyses-with-the-snakemake-workflow-system">Automating your
analyses with the snakemake workflow system</a>. You can use snakemake
inside of an srun or sbatch script!</p>
<p>CHALLENGE: Try using srun to run the following commands:</p>
<pre><code>conda activate snakemake
cd ~/snakemake_lesson
rm *.zip *.html
snakemake -j 1</code></pre>
<p>How would you run this with more CPUs? Hint: you need to modify BOTH
your srun command AND your snakemake command.</p>
<p>How would you modify the sbatch script in <a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#a-stock-sbatch-script-that-includes-activating-a-conda-environment">A stock sbatch script that includes activating a conda environment</a> to run this in an sbatch environment?</p>
</div>
<div id="monitoring-your-jobs-with-squeue" class="section level3" number="10.3.3">
<h3><span class="header-section-number">10.3.3</span> Monitoring your jobs with <code>squeue</code></h3>
<p>Oftentimes we submit jobs and would like to know certain things about
them – if they’ve started, how long they’ve been running, if they are
<em>still</em> running, etc, etc… We can look at the status of any job
Slurm is handling by using <code>squeue</code></p>
<p>If we type</p>
<pre><code>squeue</code></pre>
<p>then we see <em>many</em> rows of jobs…</p>
<pre><code>         JOBID PARTITION     NAME     USER ST        TIME  NODES CPU MIN_ME NODELIST(REASON)
      15218450       bmh this_is_ keyu1996 CG       31:10      1 2   100G   bm3
      15219413       bmh     pigz   aminio CG        0:01      1 8   4G     bm2
15108157_[34-4   bigmemm  mapping gfburgue PD        0:00      1 8   200G   (Resources)
14204771_[1182       med freebaye eoziolor PD        0:00      1 4   2000M  (AssocGrpCpuLimit)
15217722_[7-23       bmm     trim hansvgdu PD        0:00      1 2   10G    (JobArrayTaskLimit)
      15113687   bigmemm AA_ophiu jgillung PD        0:00      1 24  200G   (Priority)
      15144078   bigmemm NT_ophiu jgillung PD        0:00      1 24  200G   (Priority)
      15144205   bigmemm AA_plant jgillung PD        0:00      1 24  200G   (Priority)
      15144210   bigmemm NT_plant jgillung PD        0:00      1 24  200G   (Priority)</code></pre>
<p>This is a list of <strong>ALL</strong> the jobs currently submitted to Slurm –
which usually quite a few! And often we won’t be able to scroll
through the list to find our job(s). So, in order to only see your own
job(s) we can specify a <strong>username</strong>:</p>
<p>If you don’t know your username, you can find it in a couple of ways:
1. the <code>whoami</code> command:</p>
<pre><code>whoami</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>with <code>$USER</code></li>
</ol>
<pre><code>echo $USER</code></pre>
<p>(Note: there are subtle differences between the two. The <code>whoami</code>
command displays the effective user id at the time the command is
entered. The <code>$USER</code> is an environment variable that is set by the
shell–it won’t work on all operating systems but it works great here!)</p>
<p>We can use the output of this to see the status of the jobs associated
with a particular username:</p>
<pre><code>squeue -u $USER</code></pre>
<pre><code>         JOBID PARTITION     NAME     USER ST        TIME  NODES CPU MIN_ME NODELIST(REASON)
      15219530       bmh ggg298-a ggg298-4  R        0:28      1 8   10G  bm14</code></pre>
<p>Much better!!</p>
<p>Not only can you check on your own job’s status but you can also check
on the status of your slurm group; here, our slurm group is <code>ctbrowngrp</code>:</p>
<pre><code>squeue -A ctbrowngrp</code></pre>
<p>You can also check on the status of particular partitions:</p>
<pre><code>squeue -p high2</code></pre>
<p>These will show you what resources are being used so you can figure
out which are free, sort of.</p>
<p><strong>Note:</strong> <code>squeue -u username</code> is how I figured out what my NODES and CPU
specs were for the srun, above.</p>
</div>
<div id="canceling-your-jobs-with-scancel" class="section level3" number="10.3.4">
<h3><span class="header-section-number">10.3.4</span> Canceling your jobs with <code>scancel</code></h3>
<p>To cancel a single job you can specify the <code>JOBID</code></p>
<pre><code>scancel &lt;job_ID&gt;</code></pre>
<p>To cancel all of the jobs that belong to you, use the <code>-u</code>flag.</p>
<pre><code>scancel -u &lt;username&gt;</code></pre>
<p>CHALLENGE: Use <code>srun</code> to set yourself up with a 10 minute session on high2; then, in the session, use <code>squeue -u</code> to find the job ID of your session; then, <code>scancel</code> it. Alternatively, you can cancel ALL your jobs with <code>scancel -u</code>.</p>
</div>
</div>
<div id="more-on-resources-and-queues-and-sharing" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> More on resources and queues and sharing</h2>
<div id="measuring-your-resource-usage" class="section level3" number="10.4.1">
<h3><span class="header-section-number">10.4.1</span> Measuring your resource usage</h3>
<p>There’s an old joke that you can tell to your kids if you want to teach
them to distrust you.</p>
<blockquote>
<p>Do you know how they figure out what the weight limits are on bridges?</p>
</blockquote>
<blockquote>
<p>They build the bridge, and then they run bigger and bigger trucks
over it until the bridge fails. Then they record the weight of the
last truck that succeeded in crossing the bridge, and use that as the
weight limit for the bridge.</p>
</blockquote>
<p>It’s funny because it’s not true…</p>
<p>…unless you’re doing big compute, in which case it’s basically exactly
that.</p>
<p>For Reasons, there is no one-size-fits-all 100% reliable way to estimate
the resources needed. But you can measure the resources used when a job
completes successfully!</p>
<p>(For this reason, I suggest that the first time you run a job, you
request more resources than you think you’ll need - more time, more
memory - and then trim it back after measuring it.)</p>
<p>There are two ways to estimate your resources.</p>
<p>First, you can use <code>/usr/bin/time -v</code> to measure the time and memory needed
to run a command.</p>
<p>You’re looking for the following output:</p>
<blockquote>
<pre><code>...
Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.03
...
Maximum resident set size (kbytes): 2516
...</code></pre>
</blockquote>
<p>The first is how much time it took, the second is the max amount of memory
(in kb) needed.</p>
<p>You can use this to measure the amount of time it takes to run a script.</p>
<p>CHALLENGE: Use <code>/usr/bin/time -v</code> to run the HelloWorld.sh
script. What resources does it need?</p>
<p>The other way is to add the following command to the bottom of your HelloWorld.sh script:</p>
<blockquote>
<p>sstat –format ‘JobID,MaxRSS,AveCPU’ -P ${SLURM_JOB_ID}.batch</p>
</blockquote>
<p>which will put the following output in your .out file:</p>
<blockquote>
<pre><code>JobID|MaxRSS|AveCPU
37971877.batch|952K|00:00.000</code></pre>
</blockquote>
<p>OPTIONAL CHALLENGE: Let’s do this to look at the snakemake workflow!</p>
<p>Steps:</p>
<ul>
<li>create the sbatch script to run snakemake - see <a href="executing-large-analyses-on-hpc-clusters-with-slurm.html#a-stock-sbatch-script-that-includes-activating-a-conda-environment">A stock sbatch script that includes activating a conda environment</a></li>
<li>remove <em>.zip and </em>.html</li>
<li>submit the script with <code>sbatch</code></li>
<li>…wait…</li>
<li>inspect the output file.</li>
</ul>
</div>
<div id="nodes-vs-cpus-vs-tasks" class="section level3" number="10.4.2">
<h3><span class="header-section-number">10.4.2</span> Nodes vs CPUs vs tasks</h3>
<p>You will at some point see slurm docs making distinctions between nodes,
tasks, and CPUs per task.</p>
<p>My advice for people just beginning to work with slurm is to ignore all
of this until you need it, and just use <code>-c</code> or <code>--cpus-per-task</code>, and
leave <code>-N</code> and <code>-n</code> set at 1 (which is the default).</p>
<p>That having been said… here’s what they mean:</p>
<ul>
<li><strong>Node</strong>: A physical box that connects memory systems with extension cards and <em>CPU cores</em>.</li>
<li><strong>CPU Core</strong>: An independent computing unit that can access a certain number of <em>CPU threads</em> with all the threads having independent input streams but sharing the core’s total memory.</li>
<li><strong>tasks</strong>: A way to organize tasks that may have multiple CPUs per each task.</li>
</ul>
<p>The <code>-c</code> flag will adjust the number of CPUs per process. Alter this
if the job is multithreaded and requires more than one CPU per task to
perform optimally. If this option is specified without the -n flag,
then as many tasks will be allocated to per node as possible. The
<code>-n</code> flag will determine the number of tasks to run. The default Slurm
setting is one CPU per task per node but is adjusted when using -c.</p>
<p><img src="slurm-nodes.png" /></p>
</div>
<div id="partitions" class="section level3" number="10.4.3">
<h3><span class="header-section-number">10.4.3</span> Partitions</h3>
<p>Partitions are the subsets of the cluster (or “partitions of the whole
cluster”) that you have access to. I am not an expert on the details,
but basically they specify (1) a set of computers and (2) a priority
for running things on</p>
<p>When you get your account on an HPC, you’ll get a listing of what you have
partitions you have access to. Here’s what my group gets on farm.</p>
<p>We have access to:</p>
<ul>
<li>low2 - low priority compute nodes</li>
<li>med2 - medium priority compute nodes</li>
<li>high2 - high priority compute nodes</li>
</ul>
<p>as well as</p>
<ul>
<li>bml - low priority big mem node (up to a TB)</li>
<li>bmm - medium priority big mem node</li>
<li>bmh - high priority big mem node</li>
</ul>
<p>The way priorities work on farm is as follows:</p>
<ul>
<li>bmh = get a dedicated computer that you purchased, within 1 minute</li>
<li>bmm = get more than what you paid for, if there’s any free resources (which is usually), but your job might be suspended if another user asks for nodes on their computer in bmh.</li>
<li>bml = get (way) more than you paid for (just like bmm) but your job might be killed and rescheduled.</li>
</ul>
<p>On bmh/bmm/bml, we have one bigmem node, so:</p>
<ul>
<li>1TB of memory max</li>
<li>96 CPU</li>
</ul>
<p>On high2/med2/low2, we have two parallel nodes, so:</p>
<ul>
<li>512 GB RAM total, 256 GB max per job</li>
<li>32 cores on one machine, 64 cores on the other machine</li>
</ul>
<p>These will all be different for your account and your compute node.
See “What are HPC clusters’ access models?” at <a href="https://hpc.ucdavis.edu/faq">the HPC FAQ</a> for how this works at UC Davis.</p>
</div>
<div id="how-to-share-within-your-group" class="section level3" number="10.4.4">
<h3><span class="header-section-number">10.4.4</span> How to share within your group</h3>
<p>Here’s the guidance I give my group:</p>
<p>Users in <code>ctbrowngrp</code> collectively share resources. Currently, this
group has priority access to 1 TB of ram and 96 CPUs on one machine,
and 256 GB RAM and up to 64 CPUs on another two machines. The big mem
machine is accessed using the big mem partition, <code>bm*</code>, while the
smaller-memory machines are accessed on <code>high2</code>/<code>med2</code>/<code>low2</code>.</p>
<p>As of February 2020, there are 31 researches who share these
resources. To manage and share these resources equitably, we have
created a set of rules for resource usage. When submitting jobs, if
you submit to a <code>bm*</code> partition, please follow these rules:</p>
<ul>
<li><code>bmh</code>/<code>high2</code>: use for 1. small-ish interactive testing 2. single-core snakemake jobs that submit other jobs. 3. only if really needed: one job that uses a reasonable amount of resources of “things that I really need to not get bumped.” Things that fall into group 3 might be very long running jobs that would otherwise always be interrupted on <code>bmm</code>/<code>med2</code> or <code>bml</code>/<code>low2</code> (e.g. &gt; 5 days), or single jobs that need to be completed in time for a grant or presentation. If your single job on <code>bmh</code>/<code>high2</code> will exceed 1/3 of the groups resources for either RAM or CPU, please notify the group prior to submitting this job.</li>
<li><code>bmm</code>/<code>med2</code>: don’t submit more than 1/3 of resources at once. This counts for cpu (96 total, so max 32) and ram (1TB total, so max 333 GB).</li>
<li><code>bml</code>/<code>low2</code>: free for all! Go hog wild! Submit to your hearts content!</li>
</ul>
<p>Note that the <code>bmm</code>/<code>bml</code> and <code>med2</code>/<code>low2</code> queues have access to the
full cluster, not just our machines; so if farm is not being highly
utilized you may be able to run <em>more</em> jobs <em>faster</em> on those nodes
than on <code>bmh</code>/<code>high2</code>.</p>
</div>
<div id="how-can-you-get-an-account-on-your-hpc" class="section level3" number="10.4.5">
<h3><span class="header-section-number">10.4.5</span> How can you get an account on your HPC?</h3>
<p>To figure out what you have access to at UC Davis, see <a href="https://hpc.ucdavis.edu/faq">the HPC
FAQ</a>, “How do I request access to HPC
clusters?”</p>
</div>
</div>
<div id="what-weve-shown-you-today." class="section level2" number="10.5">
<h2><span class="header-section-number">10.5</span> What we’ve shown you today.</h2>
<p>We’ve discussed how a computer cluster differs from a single remote computer:
you have far more resources at your fingertips, but you need to deal
with the added complexity of slurm (or another scheduler).</p>
<p>We’ve shown you how to reserve a node interactively (with srun) or
for a script (with sbatch).</p>
<p>We’ve given you <em>some</em> tips and tricks for using clusters effectively.</p>
<p>We’ve shown you how to track and examine running jobs.</p>
<p>And, finally, we’ve given you a few different ways to measure resource
use, along with some suggestions on how to be a good person and share
nicely.</p>
<p>You may never need to use a really big compute cluster to run
things. But if you do, you’re at least ready to get started :)</p>
</div>
<div id="some-final-thoughts-before-departing-farm-and-moving-into-the-cloud." class="section level2" number="10.6">
<h2><span class="header-section-number">10.6</span> Some final thoughts before departing farm and moving into the cloud.</h2>
<p>This is the last time we’ll use farm. &lt;waves goodbye&gt;</p>
<p>For our last and final workshop in this series, <a href="making-use-of-on-demand-cloud-computers-from-amazon-web-services.html#making-use-of-on-demand-cloud-computers-from-amazon-web-services">Making use of
on-demand “cloud” computers from Amazon Web Services</a>, we’ll show you
how to rent computers from Amazon. In our view, this is a great
fallback when you have a burst computing need, or don’t have access to
specific resources that you need (like GPUs).</p>
<p>Importantly, most of the stuff we’ve learned for remote computing will
work just fine no matter what system we use. Shell, text editing,
ssh, conda, project organization, shell scripting, version control,
and snakemake will all work on any modern UNIX system.</p>
<p>…and that’s why we taught them to you :).</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="automating-your-analyses-with-the-snakemake-workflow-system.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="making-use-of-on-demand-cloud-computers-from-amazon-web-services.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ngs-docs/2021-august-remote-computing/edit/main/10-hpc-slurm.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ngs-docs/2021-august-remote-computing/blob/main/10-hpc-slurm.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
